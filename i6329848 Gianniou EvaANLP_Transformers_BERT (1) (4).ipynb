{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "kQhSjlX8LrSF",
        "j8El2dcG_FKs",
        "z6lcm9mn_ndK",
        "Eg29QtlmXx2_",
        "FNSb2vhtFOzp"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c90851b11daf4598b6b458c340af7353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1160c8e2c4ad49e6ba147a2df421c190",
              "IPY_MODEL_1ea78f8fcf9e4eb2b97c37fb38b7f637",
              "IPY_MODEL_e810413ab4fe4f9da1bc70b96bc5dba5"
            ],
            "layout": "IPY_MODEL_af4c166526dd467c87e1a6a620352f76"
          }
        },
        "1160c8e2c4ad49e6ba147a2df421c190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abf49ac757674f0d85cca602721f0ec6",
            "placeholder": "​",
            "style": "IPY_MODEL_7a8e516d83964585b2857ce7a6a9b048",
            "value": "Downloading: 100%"
          }
        },
        "1ea78f8fcf9e4eb2b97c37fb38b7f637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_894de8d29efb46659a6c3b09cbb8ce6c",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e068793b24af46ab837afa83e0b4cc7d",
            "value": 231508
          }
        },
        "e810413ab4fe4f9da1bc70b96bc5dba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a90e58e196a84967a518563c8720e36a",
            "placeholder": "​",
            "style": "IPY_MODEL_c4fea5fddebf462e8994a546b2fba940",
            "value": " 232k/232k [00:00&lt;00:00, 1.70MB/s]"
          }
        },
        "af4c166526dd467c87e1a6a620352f76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abf49ac757674f0d85cca602721f0ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8e516d83964585b2857ce7a6a9b048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "894de8d29efb46659a6c3b09cbb8ce6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e068793b24af46ab837afa83e0b4cc7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a90e58e196a84967a518563c8720e36a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4fea5fddebf462e8994a546b2fba940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "150c1c0952f4418f846db77d8904c0d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f097984516c41e295a589c81790ec63",
              "IPY_MODEL_5156e4a2bd9b46a4820c91a5bba272ac",
              "IPY_MODEL_5076a1ab595e4ebfa63e323f0cc670ab"
            ],
            "layout": "IPY_MODEL_80ac7fd0a11d4a379f9dcc8e5e917751"
          }
        },
        "8f097984516c41e295a589c81790ec63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbd3cd04ad2f447cb3792541e07d2806",
            "placeholder": "​",
            "style": "IPY_MODEL_928aeb419a0641ef86b7c15802b75a6c",
            "value": "Downloading: 100%"
          }
        },
        "5156e4a2bd9b46a4820c91a5bba272ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25ec1527090a43b49701bd70fb1b3a61",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6460e5345e2b4540b7303b6b4d691818",
            "value": 28
          }
        },
        "5076a1ab595e4ebfa63e323f0cc670ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1257fa0559074cae927998b38bdf2695",
            "placeholder": "​",
            "style": "IPY_MODEL_dca64d16a95a4975b250fbc7578bcf82",
            "value": " 28.0/28.0 [00:00&lt;00:00, 476B/s]"
          }
        },
        "80ac7fd0a11d4a379f9dcc8e5e917751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbd3cd04ad2f447cb3792541e07d2806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "928aeb419a0641ef86b7c15802b75a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25ec1527090a43b49701bd70fb1b3a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6460e5345e2b4540b7303b6b4d691818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1257fa0559074cae927998b38bdf2695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dca64d16a95a4975b250fbc7578bcf82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36fdac90bdd04c5d98dee2d5841ff27f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a76fa588308b4291b30220885ff53e49",
              "IPY_MODEL_d1e1dd669b7e425f9af111c1b4c34cd3",
              "IPY_MODEL_35f3ce2c50504ed69f8d0ef94b76b499"
            ],
            "layout": "IPY_MODEL_b30765ae43c943bc85d8ae99c33ddc0e"
          }
        },
        "a76fa588308b4291b30220885ff53e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aedf7277ab3c416097f3766d457a50e9",
            "placeholder": "​",
            "style": "IPY_MODEL_f05cb8abe11145d787b89bfa6370c391",
            "value": "Downloading: 100%"
          }
        },
        "d1e1dd669b7e425f9af111c1b4c34cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed32d790f8114ad6824997e5af63d07f",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9146a94ee7a54169a96c270f1c98bf8b",
            "value": 570
          }
        },
        "35f3ce2c50504ed69f8d0ef94b76b499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1289dfc07ac449aa198c286bbf0799c",
            "placeholder": "​",
            "style": "IPY_MODEL_222af359ed054ec984de99d22c1aac84",
            "value": " 570/570 [00:00&lt;00:00, 4.95kB/s]"
          }
        },
        "b30765ae43c943bc85d8ae99c33ddc0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aedf7277ab3c416097f3766d457a50e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f05cb8abe11145d787b89bfa6370c391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed32d790f8114ad6824997e5af63d07f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9146a94ee7a54169a96c270f1c98bf8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1289dfc07ac449aa198c286bbf0799c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "222af359ed054ec984de99d22c1aac84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29dea5c85cf541c49a8f7c66bc27a176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84bc03aead804fe3b2f77c0054f0bcdf",
              "IPY_MODEL_84c48cb4773347f484ccab683b82b1df",
              "IPY_MODEL_e7087df6f07c47638bb672470e3fa7ac"
            ],
            "layout": "IPY_MODEL_033a99424f5544918b2f5412f27b6f8d"
          }
        },
        "84bc03aead804fe3b2f77c0054f0bcdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_877b01f903844fc899317c36f6a84d42",
            "placeholder": "​",
            "style": "IPY_MODEL_085f596a599e47c7a814f8d02170bf29",
            "value": "Downloading: 100%"
          }
        },
        "84c48cb4773347f484ccab683b82b1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_698009ceae334085b9cc6de0915faa44",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8367a9bb6b1048aa9da707deda7c2b5a",
            "value": 440473133
          }
        },
        "e7087df6f07c47638bb672470e3fa7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff214e6fd63f4457b05d061355db0029",
            "placeholder": "​",
            "style": "IPY_MODEL_c48ebfe815344ec5b4f4c3a1c7e34759",
            "value": " 440M/440M [00:20&lt;00:00, 23.7MB/s]"
          }
        },
        "033a99424f5544918b2f5412f27b6f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "877b01f903844fc899317c36f6a84d42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "085f596a599e47c7a814f8d02170bf29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "698009ceae334085b9cc6de0915faa44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8367a9bb6b1048aa9da707deda7c2b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff214e6fd63f4457b05d061355db0029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48ebfe815344ec5b4f4c3a1c7e34759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22750072665f47cba0bbdcf55c19900d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce816309582146b7affcf6ec863776f2",
              "IPY_MODEL_6c41af6a01954435a338194b617b5237",
              "IPY_MODEL_b402d59fa4224f21ad10b25f9a161d90"
            ],
            "layout": "IPY_MODEL_bccf47b87c504f8caed8c0e70a0f4807"
          }
        },
        "ce816309582146b7affcf6ec863776f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a001ae00cfe4d2689071712fba03629",
            "placeholder": "​",
            "style": "IPY_MODEL_3e17db3b1946441b8a914241b46a5dee",
            "value": "Downloading builder script: 100%"
          }
        },
        "6c41af6a01954435a338194b617b5237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e3433ae666944539e72934e9e041ab2",
            "max": 4313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d79aceeba8f8420eb47c99f0cd4963c7",
            "value": 4313
          }
        },
        "b402d59fa4224f21ad10b25f9a161d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b703f4c443654d099601f6339aa0b075",
            "placeholder": "​",
            "style": "IPY_MODEL_08bf966551ca4a2bbfde761174d3a200",
            "value": " 4.31k/4.31k [00:00&lt;00:00, 50.4kB/s]"
          }
        },
        "bccf47b87c504f8caed8c0e70a0f4807": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a001ae00cfe4d2689071712fba03629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e17db3b1946441b8a914241b46a5dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e3433ae666944539e72934e9e041ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d79aceeba8f8420eb47c99f0cd4963c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b703f4c443654d099601f6339aa0b075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08bf966551ca4a2bbfde761174d3a200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44c6a892b26048cf9ca44eaed7e30332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ab719d2eb6e4332b97d17108b0d4c35",
              "IPY_MODEL_71947082a93644d895ae40567e23c127",
              "IPY_MODEL_facbd767d3ca4f3593b65bd032d795fa"
            ],
            "layout": "IPY_MODEL_04f44e8496d244ae94c4d763a1102245"
          }
        },
        "7ab719d2eb6e4332b97d17108b0d4c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc28c74422d6421c91d62a1f87159a19",
            "placeholder": "​",
            "style": "IPY_MODEL_9dc5864bddfb47ecbae216dd70be9dc5",
            "value": "Downloading metadata: 100%"
          }
        },
        "71947082a93644d895ae40567e23c127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11b644504b4d4d20ab5e0cecbfbed89e",
            "max": 2166,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23454c7b9d274e2c809868bf7bc999fb",
            "value": 2166
          }
        },
        "facbd767d3ca4f3593b65bd032d795fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f20fbad7e694fca83bad610bfd98ccf",
            "placeholder": "​",
            "style": "IPY_MODEL_cdab3e968b33466d877a5cb303e51f9a",
            "value": " 2.17k/2.17k [00:00&lt;00:00, 30.6kB/s]"
          }
        },
        "04f44e8496d244ae94c4d763a1102245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc28c74422d6421c91d62a1f87159a19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dc5864bddfb47ecbae216dd70be9dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11b644504b4d4d20ab5e0cecbfbed89e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23454c7b9d274e2c809868bf7bc999fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f20fbad7e694fca83bad610bfd98ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdab3e968b33466d877a5cb303e51f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1141cfc750f0467da618c9f51b3d7900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8425fcc92604668a01a97ac30285b36",
              "IPY_MODEL_b39aa15aee5548daae7eeba867100444",
              "IPY_MODEL_3162ffd79e31483e847ef29c599ca0bd"
            ],
            "layout": "IPY_MODEL_a0ec08a585a442d3a9276d5cb55b3028"
          }
        },
        "a8425fcc92604668a01a97ac30285b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ccc49969dd340b9a72f74f0aa12a2e4",
            "placeholder": "​",
            "style": "IPY_MODEL_480ee92d88b94c81956ca2ecb8e3c8a4",
            "value": "Downloading readme: 100%"
          }
        },
        "b39aa15aee5548daae7eeba867100444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e67487bda284c94a36682b6b0f7ea65",
            "max": 7590,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4393e771f654786ad556ed76652c867",
            "value": 7590
          }
        },
        "3162ffd79e31483e847ef29c599ca0bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cf0ddb95a14438999966a66a80a6833",
            "placeholder": "​",
            "style": "IPY_MODEL_0e07131ac4324ebdbbed1e15e3cc17be",
            "value": " 7.59k/7.59k [00:00&lt;00:00, 99.3kB/s]"
          }
        },
        "a0ec08a585a442d3a9276d5cb55b3028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ccc49969dd340b9a72f74f0aa12a2e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "480ee92d88b94c81956ca2ecb8e3c8a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e67487bda284c94a36682b6b0f7ea65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4393e771f654786ad556ed76652c867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cf0ddb95a14438999966a66a80a6833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e07131ac4324ebdbbed1e15e3cc17be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e4f3eeb4af44efb9e75a3734ae1a66d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eda208717307420d8418b04a02d32210",
              "IPY_MODEL_8ff1b67e3be74c35b124cf5940729118",
              "IPY_MODEL_c5c36259c9664347bfa0033145112321"
            ],
            "layout": "IPY_MODEL_7981a3dc73e24b4d9364c722bd09ae26"
          }
        },
        "eda208717307420d8418b04a02d32210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e41382ef33b44afdaa5dbee6425f0811",
            "placeholder": "​",
            "style": "IPY_MODEL_b2a685ba4e7f4b7a8616a64c0a38be90",
            "value": "Downloading data: 100%"
          }
        },
        "8ff1b67e3be74c35b124cf5940729118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79b92f4355c14ba58055640e56c15996",
            "max": 84125825,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88259d1432764c4dbd481882b64be29a",
            "value": 84125825
          }
        },
        "c5c36259c9664347bfa0033145112321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e997379d4c44c8b3838b0d7e167002",
            "placeholder": "​",
            "style": "IPY_MODEL_73cdb8b1d9b14015b02535f6eb3239fc",
            "value": " 84.1M/84.1M [00:06&lt;00:00, 34.3MB/s]"
          }
        },
        "7981a3dc73e24b4d9364c722bd09ae26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e41382ef33b44afdaa5dbee6425f0811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a685ba4e7f4b7a8616a64c0a38be90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79b92f4355c14ba58055640e56c15996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88259d1432764c4dbd481882b64be29a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8e997379d4c44c8b3838b0d7e167002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73cdb8b1d9b14015b02535f6eb3239fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c5695f4747e46fba8073c32dd0cb462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9051657fd5394174b13bbda36498cf8f",
              "IPY_MODEL_5e417fce7a40476ab3fb6eb94c769876",
              "IPY_MODEL_32d44ba6979f41fa9b148c50a573dc37"
            ],
            "layout": "IPY_MODEL_f68bf7dcbf7646439ae030e85c423721"
          }
        },
        "9051657fd5394174b13bbda36498cf8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4828edcd2877458b97b444a9c37e4a1e",
            "placeholder": "​",
            "style": "IPY_MODEL_ed1dfbdb839f4a41a7a631c3de1d7c02",
            "value": "Generating train split: 100%"
          }
        },
        "5e417fce7a40476ab3fb6eb94c769876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_696d28ea73944bbd9071eccdc23324ef",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53a37e9d5f1e467fa579c64694e36afd",
            "value": 25000
          }
        },
        "32d44ba6979f41fa9b148c50a573dc37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b8ff99ecdf44f3cb3b132d3bfce60db",
            "placeholder": "​",
            "style": "IPY_MODEL_55ee971ca20c44e19417ae1e252f85b9",
            "value": " 25000/25000 [00:22&lt;00:00, 6327.24 examples/s]"
          }
        },
        "f68bf7dcbf7646439ae030e85c423721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "4828edcd2877458b97b444a9c37e4a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed1dfbdb839f4a41a7a631c3de1d7c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "696d28ea73944bbd9071eccdc23324ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53a37e9d5f1e467fa579c64694e36afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b8ff99ecdf44f3cb3b132d3bfce60db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55ee971ca20c44e19417ae1e252f85b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "577f0cd46f174965aadc5ebcf92280dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7630641f7620454091713231f350c3ce",
              "IPY_MODEL_efe0c10d61e94809a32f69b462de26a9",
              "IPY_MODEL_ce61d5a5af9a4caca2e0d682c02d82a6"
            ],
            "layout": "IPY_MODEL_948422e5f11b4a379be299158fcdfd30"
          }
        },
        "7630641f7620454091713231f350c3ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0db6003fe804a72a51faadabe1931e2",
            "placeholder": "​",
            "style": "IPY_MODEL_7e12760612d0457795a1fcc1f8da8cdb",
            "value": "Generating test split: 100%"
          }
        },
        "efe0c10d61e94809a32f69b462de26a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a07efab818461f9924795a1a10d748",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_756cbd099874438e80fdbe4ad2195757",
            "value": 25000
          }
        },
        "ce61d5a5af9a4caca2e0d682c02d82a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b1a455635854ad588e585b1e2f48f25",
            "placeholder": "​",
            "style": "IPY_MODEL_bcd814a4bc8e4d76a1f9dd954254a2a7",
            "value": " 25000/25000 [00:22&lt;00:00, 6576.57 examples/s]"
          }
        },
        "948422e5f11b4a379be299158fcdfd30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a0db6003fe804a72a51faadabe1931e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e12760612d0457795a1fcc1f8da8cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74a07efab818461f9924795a1a10d748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "756cbd099874438e80fdbe4ad2195757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b1a455635854ad588e585b1e2f48f25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcd814a4bc8e4d76a1f9dd954254a2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6393de89a2fe4d7499d5e680c8964a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b314e03a72334120813ea236050ba362",
              "IPY_MODEL_aae79434101d4084989e0a9406aad888",
              "IPY_MODEL_a9d0bcd59acb4db3b2c7c143ada079e9"
            ],
            "layout": "IPY_MODEL_b1044c5b63c0442284005199dcf0cfd2"
          }
        },
        "b314e03a72334120813ea236050ba362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_500d04dd845d453d875efe70d2cdf48c",
            "placeholder": "​",
            "style": "IPY_MODEL_5f6bf2ac777e4311b8b6eab67649a9a6",
            "value": "Generating unsupervised split:  99%"
          }
        },
        "aae79434101d4084989e0a9406aad888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ec526c560b4484a98dbd14a6c8a549a",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdd7fedf064e4146ae7f271dda25b241",
            "value": 50000
          }
        },
        "a9d0bcd59acb4db3b2c7c143ada079e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5142ff731634423889d32fc714c7ab8",
            "placeholder": "​",
            "style": "IPY_MODEL_375e77475d8c409985620010c36b34b8",
            "value": " 49393/50000 [00:15&lt;00:00, 6893.19 examples/s]"
          }
        },
        "b1044c5b63c0442284005199dcf0cfd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "500d04dd845d453d875efe70d2cdf48c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f6bf2ac777e4311b8b6eab67649a9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ec526c560b4484a98dbd14a6c8a549a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd7fedf064e4146ae7f271dda25b241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5142ff731634423889d32fc714c7ab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375e77475d8c409985620010c36b34b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cda79b674acc4f82aa97e0ca354a5c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_671f7310e29e401e8e15fbf9a8e85488",
              "IPY_MODEL_5b809857934a4186aa442ea894947dd4",
              "IPY_MODEL_c57e1a7fe24742d297d0420a24af44e7"
            ],
            "layout": "IPY_MODEL_c891c8eb378447059e1a9a5e4716b9bc"
          }
        },
        "671f7310e29e401e8e15fbf9a8e85488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e7b157deacd484fb2e3234ffbcdbfbb",
            "placeholder": "​",
            "style": "IPY_MODEL_3d1923196fe140fcb3da0b204731ac9d",
            "value": "Downloading: 100%"
          }
        },
        "5b809857934a4186aa442ea894947dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab33e911fa4840b3b2991fb44327df84",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1eb3dff7fa143c2999afc048d35c160",
            "value": 466062
          }
        },
        "c57e1a7fe24742d297d0420a24af44e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25eb838c6f30488aadb1ad4317f2ac2d",
            "placeholder": "​",
            "style": "IPY_MODEL_c7353d4c97a14b539429b2b10f023feb",
            "value": " 466k/466k [00:00&lt;00:00, 1.63MB/s]"
          }
        },
        "c891c8eb378447059e1a9a5e4716b9bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e7b157deacd484fb2e3234ffbcdbfbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d1923196fe140fcb3da0b204731ac9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab33e911fa4840b3b2991fb44327df84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1eb3dff7fa143c2999afc048d35c160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25eb838c6f30488aadb1ad4317f2ac2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7353d4c97a14b539429b2b10f023feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4977af27c68146659c757bb11f480acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d83c4739f074fb4a8c2a92962edd97e",
              "IPY_MODEL_916101eb20dc407485bc15d52be33969",
              "IPY_MODEL_409651118c1b4ee9b159b5010ab46ca3"
            ],
            "layout": "IPY_MODEL_eb54fbae80c64d17a5bce7d485cd6416"
          }
        },
        "0d83c4739f074fb4a8c2a92962edd97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a52419f7d94b9299494de430276d59",
            "placeholder": "​",
            "style": "IPY_MODEL_4a0154107d8947379507539d22a181cd",
            "value": "100%"
          }
        },
        "916101eb20dc407485bc15d52be33969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d89bdeb61c94e19910fd7081d88889b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b59502c1ee8465ca4b75e89adb07d39",
            "value": 1
          }
        },
        "409651118c1b4ee9b159b5010ab46ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99372228995f4b34bb6d887d8cde10cc",
            "placeholder": "​",
            "style": "IPY_MODEL_f21f7f7aafda45dd9cbf197800668f33",
            "value": " 1/1 [00:06&lt;00:00,  6.23s/ba]"
          }
        },
        "eb54fbae80c64d17a5bce7d485cd6416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09a52419f7d94b9299494de430276d59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a0154107d8947379507539d22a181cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d89bdeb61c94e19910fd7081d88889b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b59502c1ee8465ca4b75e89adb07d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99372228995f4b34bb6d887d8cde10cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f21f7f7aafda45dd9cbf197800668f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc77fdd4e6744f0280b9120337d55d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50fd4db9a6b648a1961692fcb17a4524",
              "IPY_MODEL_e081a14d34084b209ce01b1ad1328f74",
              "IPY_MODEL_0ad7b9b376334b5c8c2e44059fcf61dc"
            ],
            "layout": "IPY_MODEL_40810f9700fe4138ab5178fbcba9bcd4"
          }
        },
        "50fd4db9a6b648a1961692fcb17a4524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4694471a75194a9290b9ad493caf2ae6",
            "placeholder": "​",
            "style": "IPY_MODEL_1a079aa0eddd4a9190b59e4481f1d88f",
            "value": "100%"
          }
        },
        "e081a14d34084b209ce01b1ad1328f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c89ac9a6c0444780b269fbf38bc4f356",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31da2753a2c04643b6326e0610b4712a",
            "value": 1
          }
        },
        "0ad7b9b376334b5c8c2e44059fcf61dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07919679cc6a4d03960925d6946cc115",
            "placeholder": "​",
            "style": "IPY_MODEL_d0ee380013fe4a67a17cf4fa5f9fc8af",
            "value": " 1/1 [00:02&lt;00:00,  2.35s/ba]"
          }
        },
        "40810f9700fe4138ab5178fbcba9bcd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4694471a75194a9290b9ad493caf2ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a079aa0eddd4a9190b59e4481f1d88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c89ac9a6c0444780b269fbf38bc4f356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31da2753a2c04643b6326e0610b4712a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07919679cc6a4d03960925d6946cc115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ee380013fe4a67a17cf4fa5f9fc8af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![maastricht-university-logo.jpeg](data:image/jpeg;base64,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)\n",
        "#Faculty of Science and Engineering - Department of Advanced Computer Sciences\n",
        "# Course Advanced Natural Language Processing - Tutorial Deep Learning and NLP: BERT\n",
        "By: Gijs Wijngaard"
      ],
      "metadata": {
        "id": "RVP_F3-hO4zT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this notebook we would need our GPU again (in the end). You can activate your GPU by clicking on *Runtime*, then *Change runtime type* and pressing *GPU*. If you hit the Google's GPU limits for usage, you can use other free GPU services such as [Kaggle GPU's ](https://kaggle.com/) (recommended), [Amazon's GPU's](https://studiolab.sagemaker.aws/) or [Paperspace Gradient](https://www.paperspace.com/gradient/notebooks) or of course your local GPU on your computer (if you have one)."
      ],
      "metadata": {
        "id": "_aFCMJo29p9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BERT and HuggingFace\n",
        "\n",
        "So far, we have worked with a various amount of BERT models. BERT has a lot to offer:\n",
        "\n",
        "a) pretrained models\n",
        "\n",
        "b) bi-directional word embeddings\n",
        "\n",
        "c) ability to deal with out-of vacabulairy words using sub-words (including byte pair enciding, byte-level byte pairing and the WordPiece tokenizer)\n",
        "\n",
        "d) mask language modeling\n",
        "\n",
        "e) next sentence prediction\n",
        "\n",
        "Remember, there are 1000's of different BERT models, varying in size (different number of encoding layers L, different number of attention heads A, different number of hidden units H), and with different pre-training data.  \n",
        "\n"
      ],
      "metadata": {
        "id": "op3dq7K_Em_2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjTrV91KLrSC"
      },
      "source": [
        "Hugging Face is an organization that is behind the very popular open-source library `transformers`. It is very useful and powerful for several NLP and NLU tasks. Transformers models work well when already pretrained, and the `transformers` library includes thousands of pre-trained models in about 100+ natural languages. Its ease of use and extendability is also a plus. You can run state-of-the-art models with just a few lines of code.\n",
        "\n",
        "We can install `transformers` (and the `datasets` library) directly using pip as shown in the following: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "o7PQZSHt_FKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec7d6320-e6df-4e7a-a0a4-2a39439d43e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.5 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 451 kB 52.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 43.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 55.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 55.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 50.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 56.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq transformers datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets make sure we get the same results every time we run the same code in the notebook (reproducability). We can do this by setting the seeds of the packages we use. Like this:"
      ],
      "metadata": {
        "id": "fHnYEcQFQq4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "miUHuY2hQqK1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vocabulary and Tokenizers"
      ],
      "metadata": {
        "id": "21r9pHeldV4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can tokenize a piece of text by importing the tokenizer from the `transformers` library. Then to tokenize we use the `tokenize()` function. This function splits the texts based on the items in the vocabulary."
      ],
      "metadata": {
        "id": "IkUZmXK1epUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "p_hMv2uZe35T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "c90851b11daf4598b6b458c340af7353",
            "1160c8e2c4ad49e6ba147a2df421c190",
            "1ea78f8fcf9e4eb2b97c37fb38b7f637",
            "e810413ab4fe4f9da1bc70b96bc5dba5",
            "af4c166526dd467c87e1a6a620352f76",
            "abf49ac757674f0d85cca602721f0ec6",
            "7a8e516d83964585b2857ce7a6a9b048",
            "894de8d29efb46659a6c3b09cbb8ce6c",
            "e068793b24af46ab837afa83e0b4cc7d",
            "a90e58e196a84967a518563c8720e36a",
            "c4fea5fddebf462e8994a546b2fba940",
            "150c1c0952f4418f846db77d8904c0d6",
            "8f097984516c41e295a589c81790ec63",
            "5156e4a2bd9b46a4820c91a5bba272ac",
            "5076a1ab595e4ebfa63e323f0cc670ab",
            "80ac7fd0a11d4a379f9dcc8e5e917751",
            "cbd3cd04ad2f447cb3792541e07d2806",
            "928aeb419a0641ef86b7c15802b75a6c",
            "25ec1527090a43b49701bd70fb1b3a61",
            "6460e5345e2b4540b7303b6b4d691818",
            "1257fa0559074cae927998b38bdf2695",
            "dca64d16a95a4975b250fbc7578bcf82",
            "36fdac90bdd04c5d98dee2d5841ff27f",
            "a76fa588308b4291b30220885ff53e49",
            "d1e1dd669b7e425f9af111c1b4c34cd3",
            "35f3ce2c50504ed69f8d0ef94b76b499",
            "b30765ae43c943bc85d8ae99c33ddc0e",
            "aedf7277ab3c416097f3766d457a50e9",
            "f05cb8abe11145d787b89bfa6370c391",
            "ed32d790f8114ad6824997e5af63d07f",
            "9146a94ee7a54169a96c270f1c98bf8b",
            "b1289dfc07ac449aa198c286bbf0799c",
            "222af359ed054ec984de99d22c1aac84"
          ]
        },
        "outputId": "04bdbc02-f684-4140-e01b-0b921a5ff9cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c90851b11daf4598b6b458c340af7353"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "150c1c0952f4418f846db77d8904c0d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36fdac90bdd04c5d98dee2d5841ff27f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT also has extra tokens involved, for example:\n",
        "\n",
        "1. The classification token `[CLS]`. This token is for classification of the transformer. We attend to this token and we can take an embedding representation of a whole sentence by just using this token. \n",
        "2. The separation token `[SEP]`. This token is to let the model know we have separate sentences within a full text we pass to the model. "
      ],
      "metadata": {
        "id": "AQq9S2rm11jD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Here is the sentence I want embeddings for.\"\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "# Tokenize our sentence with the BERT tokenizer.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "# Print out the tokens.\n",
        "tokenized_text"
      ],
      "metadata": {
        "id": "xM7H5JkefIRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf263dd3-3499-42ba-c796-e5c15c678fcb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'here',\n",
              " 'is',\n",
              " 'the',\n",
              " 'sentence',\n",
              " 'i',\n",
              " 'want',\n",
              " 'em',\n",
              " '##bed',\n",
              " '##ding',\n",
              " '##s',\n",
              " 'for',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This text is not yet something we can pass through our model yet. For that, we need it converted to integers (ids). We can do this with the `convert_tokens_to_ids` function:"
      ],
      "metadata": {
        "id": "Nk4bnxAd1mmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenized_text)"
      ],
      "metadata": {
        "id": "mICf1JCk1ebY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "004bd827-acbe-4a9c-8790-246506105996"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 2182,\n",
              " 2003,\n",
              " 1996,\n",
              " 6251,\n",
              " 1045,\n",
              " 2215,\n",
              " 7861,\n",
              " 8270,\n",
              " 4667,\n",
              " 2015,\n",
              " 2005,\n",
              " 1012,\n",
              " 102]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function just looks up the tokens in the vocabulary. For example, the id 5000 means `knight`, because it is the 5000th index in the vocabulary:"
      ],
      "metadata": {
        "id": "CflPdyWr3zqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(tokenizer.vocab.keys())[5000:5020]"
      ],
      "metadata": {
        "id": "ZRywEv0Z3zJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6427a6d-6a0c-40b6-8c5b-d5ad49ea1df3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['knight',\n",
              " 'lap',\n",
              " 'survey',\n",
              " 'ma',\n",
              " '##ow',\n",
              " 'noise',\n",
              " 'billy',\n",
              " '##ium',\n",
              " 'shooting',\n",
              " 'guide',\n",
              " 'bedroom',\n",
              " 'priest',\n",
              " 'resistance',\n",
              " 'motor',\n",
              " 'homes',\n",
              " 'sounded',\n",
              " 'giant',\n",
              " '##mer',\n",
              " '150',\n",
              " 'scenes']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can convert ids back to tokens with the `convert_ids_to_tokens` function:"
      ],
      "metadata": {
        "id": "4qy-eYrP5eky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "tokenizer.convert_ids_to_tokens(ids)"
      ],
      "metadata": {
        "id": "i2wULAmP5PvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88301488-40f6-43b4-82ca-5864bbee81f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'here',\n",
              " 'is',\n",
              " 'the',\n",
              " 'sentence',\n",
              " 'i',\n",
              " 'want',\n",
              " 'em',\n",
              " '##bed',\n",
              " '##ding',\n",
              " '##s',\n",
              " 'for',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normally, we would just use `encode` or `encode_plus`. `encode` adds the `CLS` and `SEP`, add the `convert_tokens_to_ids` and `tokenize` steps into one step. `encode_plus` does this and also appends a `attention_mask` and `token_type_ids`. "
      ],
      "metadata": {
        "id": "GOQcC1RU2-IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(text)"
      ],
      "metadata": {
        "id": "p7a4dC1O3b8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34fae080-d654-43e3-dc8f-e2355a9f10ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 2182,\n",
              " 2003,\n",
              " 1996,\n",
              " 6251,\n",
              " 1045,\n",
              " 2215,\n",
              " 7861,\n",
              " 8270,\n",
              " 4667,\n",
              " 2015,\n",
              " 2005,\n",
              " 1012,\n",
              " 102]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQhSjlX8LrSF"
      },
      "source": [
        "## BERT Models\n",
        "In this section, we will learn how to extract embeddings from the pre-trained BERT. Consider the sentence 'I love Maastricht'. Let's see how to obtain the contextualized word embedding of all the words in the sentence using the pre-trained BERT model with Hugging Face's transformer library. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_k8AHt0LrSH"
      },
      "source": [
        "Lets consider the `HuggingFace` library. We can check all the available pre-trained models [here](https://huggingface.co/models). For BERT, these models we can filter down on the `bert` [tag](https://huggingface.co/models?other=bert). For now, we use the [bert-base-uncased](https://huggingface.co/bert-base-uncased) model. As the name suggests, it a BERT with 12 encoders and it is trained with uncased tokens. The representation size will be 768. The `uncased` means that we have only lowercase letters in our tokenizer. \n",
        "\n",
        "We can download and load the pretrained model like this. Lets look how the model is implemented. Can you notice the 12 layers/encoders of the model? Also notice the different type of inputs we have in the embedding layer. The word embedding, that converts the token ids we have (30522 of them) into 768. Same holds for the position embeddings and the token_type_embeddings we could put in. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "swqqjz08_FKj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "29dea5c85cf541c49a8f7c66bc27a176",
            "84bc03aead804fe3b2f77c0054f0bcdf",
            "84c48cb4773347f484ccab683b82b1df",
            "e7087df6f07c47638bb672470e3fa7ac",
            "033a99424f5544918b2f5412f27b6f8d",
            "877b01f903844fc899317c36f6a84d42",
            "085f596a599e47c7a814f8d02170bf29",
            "698009ceae334085b9cc6de0915faa44",
            "8367a9bb6b1048aa9da707deda7c2b5a",
            "ff214e6fd63f4457b05d061355db0029",
            "c48ebfe815344ec5b4f4c3a1c7e34759"
          ]
        },
        "outputId": "a927cdc4-63e9-4690-ca7c-0ec6a49e50c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29dea5c85cf541c49a8f7c66bc27a176"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8El2dcG_FKs"
      },
      "source": [
        "## Preprocessing the input \n",
        "Define the sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "8Hkc5o3B_FKu"
      },
      "outputs": [],
      "source": [
        "sentence = 'I love AI'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVn3-2XM_FKv"
      },
      "source": [
        "Tokenize the sentence and obtain the tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "4Ui-3oWr_FKw"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.tokenize(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSYRLcvV_FKy"
      },
      "source": [
        "Let's print the tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CGHtPj5H_FKz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc925d34-b984-42f0-988a-f71b2cb8907f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'love', 'ai']\n"
          ]
        }
      ],
      "source": [
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL8VgpcM_FK0"
      },
      "source": [
        "Now, we will add the `[CLS]` token at the beginning and `[SEP]` token at the end of the tokens list: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "3CpARvDc_FK0"
      },
      "outputs": [],
      "source": [
        "tokens = ['[CLS]'] + tokens + ['[SEP]']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbFEyrk7_FK2"
      },
      "source": [
        "Let's look at our updated tokens list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Uaf_JScw_FK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a2a438-ea23-437a-b8c0-b09380b655d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'i', 'love', 'ai', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVD29L7A_FK3"
      },
      "source": [
        "As we can observe, we have `[CLS]` token at the beginning and sep token at the end of our tokens list. We can also observe that length of our tokens is 5.\n",
        "\n",
        "Say, we need to keep the length of our tokens list to 7, then, in that case, we will add two `[PAD]` tokens at the end as shown in the following:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "cqMI--rA_FK4"
      },
      "outputs": [],
      "source": [
        "tokens = tokens + ['[PAD]'] + ['[PAD]']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEEHs7CV_FK6"
      },
      "source": [
        "Let's print our updated tokens list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2tKmh_hk_FK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f37519cb-4ecb-420d-9051-41e7532ae318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'i', 'love', 'ai', '[SEP]', '[PAD]', '[PAD]']\n"
          ]
        }
      ],
      "source": [
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPd9TPWE_FK7"
      },
      "source": [
        "\n",
        "\n",
        "As we can observe, now we have the tokens list consists of `[PAD]` tokens and the length of our tokens list is 7. \n",
        "\n",
        "Next, we create the attention mask. The attention mask is there to let the model know which items should be taken into account when calculating the attentions. Since `[PAD]` tokens are just to pad the string and do not have any semantic meaning, we should let the model know not to take them into account. \n",
        "\n",
        "We set the attention mask value to 1 if the token is not a `[PAD]` token else we will set the attention mask to 0 as shown below:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "3SbiaBws_FK8"
      },
      "outputs": [],
      "source": [
        "attention_mask1 = [1 if i!= '[PAD]' else 0 for i in tokens]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SELKgxsG_FK9"
      },
      "source": [
        "Let's print the attention_mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NmtZKFFq_FK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467db76a-16e4-4f19-c40f-367236be1ca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(attention_mask1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvtvC8HW_FK-"
      },
      "source": [
        "\n",
        "As we can observe, we have attention mask values 0 at the position where have `[PAD]` token and 1 at other positions. \n",
        "\n",
        "Next, we convert all the tokens to their token_ids as shown below: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "id": "KGbsHfxL_FK_"
      },
      "outputs": [],
      "source": [
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaQWwz_y_FK_"
      },
      "source": [
        "\n",
        "Let's have a look at the token_ids:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iih_wWeT_FLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "387f2dc4-6bb5-4392-d10f-9239615e056c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1045, 2293, 9932, 102, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9RL1cBs_FLA"
      },
      "source": [
        "\n",
        "From the above output, we can observe that each token is mapped to a unique token id.\n",
        "\n",
        "Now, we convert the token_ids and attention_mask to tensors as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "id": "KQzsDUez_FLB"
      },
      "outputs": [],
      "source": [
        "token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
        "attention_mask1 = torch.tensor(attention_mask1).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQn5de_a_FLC"
      },
      "source": [
        "\n",
        "That's it. Next, we feed the token_ids and attention_mask to the pre-trained BERT model and get the embedding. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYIDWAO-_FLD"
      },
      "source": [
        "## Getting the embedding \n",
        "\n",
        "As shown in the following code, we feed the token_ids, and attention_mask to the model and get the output of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "id": "Rh-Ohh71_FLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64dba6d8-112e-4c8b-bb6b-b8fd354807bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 101, 1045, 2293, 9932,  102,    0,    0]])\n",
            "tensor([[1, 1, 1, 1, 1, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "print(token_ids)\n",
        "print(attention_mask1)\n",
        "last_hidden_state, pooler_output = model(token_ids, attention_mask = attention_mask1).to_tuple()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3Kfvd3F_FLF"
      },
      "source": [
        "This output contains two keys or more keys, depending on the task at hand. In the case of `bert-base-uncased`, we get "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Gx1RfsaU_FLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a8b854-6814-4a0e-b912-e5d75c5e1c34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 7, 768]), torch.Size([1, 768]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "last_hidden_state.shape, pooler_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `pooler_output` is basically the `last_hidden_state`'s `[CLS]` token through the pooling module (linear layer + activation) at the end:"
      ],
      "metadata": {
        "id": "9Dsj4xWesaSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.allclose(pooler_output, model.pooler(last_hidden_state))"
      ],
      "metadata": {
        "id": "C4IjdcYzs6HX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c746aa-6e6a-4eaa-f09d-246d2b714f58"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWxFowIS_FLG"
      },
      "source": [
        "The size `[1,7,768]` indicates the `[batch_size, sequence_length, hidden_size]`.\n",
        "\n",
        "Our batch size is 1, the sequence length is the token length, since we have 7 tokens, the sequence length is 7, and the hidden size is the representation (embedding) size and it is 768 for the BERT-base model. \n",
        "\n",
        "We can obtain the representation of each token as: \n",
        "\n",
        "- `output.last_hidden_state[0][0]` gives the representation of the first token which is `[CLS]`\n",
        "- `output.last_hidden_state[0][1]` gives the representation of the second token which is 'I' \n",
        "- `output.last_hidden_state[0][2]` gives the representation of the third token which is 'love'.\n",
        "\n",
        "We can also index it with `output.last_hidden_state[:, 0, :]`. In this way, we specify that we want to have the zeroth element on the second index, we get a matrix in return with both the batch size and the embedding size (since we put a colon there).\n",
        "\n",
        "In this way, we can obtain the contextual representation of all the tokens. This is basically the contextualized word embeddings of all the words in the given sentence. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1\n",
        "1. Now write your own code. Put the following text (the one defined under here with three times `bank` in it) to the tokenizer, add `[CLS]` and `[SEP]` values to it and pass it through the model. Get the vector representations of each of the three tokens of `bank` in the sentence and compare them. \n",
        "2. How does this differ from putting the text through a Word2Vec model? \n",
        "2. Put a string with only \"bank\" (add `[CLS]` and `[SEP]`) through the tokenizer and model. How does this vector of the word \"bank\" differ from the other \"bank\" vectors?"
      ],
      "metadata": {
        "id": "zzsYzhiRaW1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WRITE YOUR ANSWER HERE\n",
        "1.All the three vectors are different.After calculationg the cos similarity for the first two 'bank' words we find high similarity(95%) as they have similar meaning..and not high similarity(70%) for the 'bank' words with the different meaning.\n",
        "2.Word2Vec models generate embeddings that are context-independent.It will generate the same single vector for all the three words 'bank'. Whereas, BERT will generate different vectors for the word bank being used in different contexts.\n",
        "3.The vector totally differs from the other vectors.The cos similarity indicates that the word meaning is different from both other meanings of the word 'bank'."
      ],
      "metadata": {
        "id": "m3u2M6MHe5Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
        "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
        "       \"fishing on the Mississippi river bank.\"\n",
        "# WRITE YOUR CODE HERE\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])\n",
        "for i, token_str in enumerate(tokenized_text):\n",
        "  print (i, token_str)\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "    hidden_states = outputs[2]\n",
        "print(outputs[0][0][6][0:5])\n",
        "print(outputs[0][0][19][0:5])\n",
        "print(outputs[0][0][10][0:5])\n",
        "\n",
        "from scipy.spatial.distance import cosine\n",
        "diff_bank = 1 - cosine(outputs[0][0][6], outputs[0][0][19])\n",
        "same_bank = 1 - cosine(outputs[0][0][6], outputs[0][0][10])\n",
        "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
        "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)\n",
        "text2= \"[CLS] \" + 'bank' + \" [SEP]\"\n",
        "marked_text2 = \"[CLS] \" + text2 + \" [SEP]\"\n",
        "tokenized_text2 = tokenizer.tokenize(marked_text2)\n",
        "indexed_tokens2 = tokenizer.convert_tokens_to_ids(tokenized_text2)\n",
        "segments_ids2 = [1] * len(tokenized_text2)\n",
        "tokens_tensor2 = torch.tensor([indexed_tokens2])\n",
        "segments_tensors2 = torch.tensor([segments_ids2])\n",
        "for i, token_str in enumerate(tokenized_text2):\n",
        "  print (i, token_str)\n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs2 = model(tokens_tensor2, segments_tensors2)\n",
        "    hidden_states2 = outputs2[2]\n",
        "print(outputs2[0][0][2][0:5])\n",
        "print(1 - cosine(outputs[0][0][6], outputs2[0][0][2]))\n",
        "print(1 - cosine(outputs[0][0][19], outputs2[0][0][2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzhqPJHu3JSu",
        "outputId": "03c37914-48b3-4ab2-b318-0b50f1ac406e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [CLS]\n",
            "1 after\n",
            "2 stealing\n",
            "3 money\n",
            "4 from\n",
            "5 the\n",
            "6 bank\n",
            "7 vault\n",
            "8 ,\n",
            "9 the\n",
            "10 bank\n",
            "11 robber\n",
            "12 was\n",
            "13 seen\n",
            "14 fishing\n",
            "15 on\n",
            "16 the\n",
            "17 mississippi\n",
            "18 river\n",
            "19 bank\n",
            "20 .\n",
            "21 [SEP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.9001, -0.5380, -0.1669,  0.2242,  0.6897])\n",
            "tensor([ 0.2961, -0.2856, -0.0382,  0.1674,  0.7713])\n",
            "tensor([ 0.7977, -0.5217, -0.1984,  0.1890,  0.5941])\n",
            "Vector similarity for  *similar*  meanings:  0.95\n",
            "Vector similarity for *different* meanings:  0.70\n",
            "0 [CLS]\n",
            "1 [CLS]\n",
            "2 bank\n",
            "3 [SEP]\n",
            "4 [SEP]\n",
            "tensor([-0.3942, -0.8264, -0.5570, -0.5478,  0.4285])\n",
            "0.36390575766563416\n",
            "0.376626580953598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Second method summing the last 4 layers\n",
        "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
        "       \"fishing on the Mississippi river bank.\"\n",
        "# WRITE YOUR CODE HERE\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "    hidden_states = outputs[2]\n",
        "token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "\n",
        "token_embeddings.size()\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "token_embeddings.size()\n",
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "token_embeddings.size()\n",
        "## creating the word vectors by summing together the last four layers\n",
        "token_vecs_sum = []\n",
        "for token in token_embeddings:\n",
        "\n",
        "    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "    \n",
        "    token_vecs_sum.append(sum_vec)\n",
        "for i, token_str in enumerate(tokenized_text):\n",
        "  print (i, token_str)\n",
        "###we will see at which indices are the words bank and use it later:\n",
        "print('First 5 vector values for each instance of \"bank\".')\n",
        "print('')\n",
        "print(\"bank vault   \", str(token_vecs_sum[6][:5]))\n",
        "print(\"bank robber  \", str(token_vecs_sum[10][:5]))\n",
        "print(\"river bank   \", str(token_vecs_sum[19][:5]))\n",
        "#the values differ, but let’s calculate the cosine similarity between the vectors to make a more precise comparison\n",
        "from scipy.spatial.distance import cosine\n",
        "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
        "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
        "\n",
        "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
        "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)\n",
        "\n",
        "text2= \"[CLS] \" + 'bank' + \" [SEP]\"\n",
        "marked_text2 = \"[CLS] \" + text2 + \" [SEP]\"\n",
        "tokenized_text2 = tokenizer.tokenize(marked_text2)\n",
        "indexed_tokens2 = tokenizer.convert_tokens_to_ids(tokenized_text2)\n",
        "segments_ids2 = [1] * len(tokenized_text2)\n",
        "tokens_tensor2 = torch.tensor([indexed_tokens2])\n",
        "segments_tensors2 = torch.tensor([segments_ids2])\n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs2 = model(tokens_tensor2, segments_tensors2)\n",
        "    hidden_states2 = outputs[2]\n",
        "token_embeddings2 = torch.stack(hidden_states2, dim=0)\n",
        "token_embeddings2 = torch.squeeze(token_embeddings2, dim=1)\n",
        "token_embeddings2 = token_embeddings.permute(1,0,2)\n",
        "## creating the word vectors by summing together the last four layers\n",
        "token_vecs_sum2 = []\n",
        "for token in token_embeddings2:\n",
        "\n",
        "    sum_vec2 = torch.sum(token[-4:], dim=0)\n",
        "    \n",
        "    token_vecs_sum2.append(sum_vec2)\n",
        "for i, token_str in enumerate(tokenized_text2):\n",
        "  print (i, token_str)\n",
        "print(\"bank \", str(token_vecs_sum2[2][:5]))\n",
        "x=1 - cosine(token_vecs_sum[10], token_vecs_sum2[2])\n",
        "print(x)\n",
        "y=1 - cosine(token_vecs_sum[19], token_vecs_sum2[2])\n",
        "print(y)"
      ],
      "metadata": {
        "id": "xDDDcEX0iywd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5af7d3a-a231-46b8-cada-2300d86f7118"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [CLS]\n",
            "1 after\n",
            "2 stealing\n",
            "3 money\n",
            "4 from\n",
            "5 the\n",
            "6 bank\n",
            "7 vault\n",
            "8 ,\n",
            "9 the\n",
            "10 bank\n",
            "11 robber\n",
            "12 was\n",
            "13 seen\n",
            "14 fishing\n",
            "15 on\n",
            "16 the\n",
            "17 mississippi\n",
            "18 river\n",
            "19 bank\n",
            "20 .\n",
            "21 [SEP]\n",
            "First 5 vector values for each instance of \"bank\".\n",
            "\n",
            "bank vault    tensor([ 3.3596, -2.9805, -1.5421,  0.7065,  2.0031])\n",
            "bank robber   tensor([ 2.7359, -2.5577, -1.3094,  0.6797,  1.6633])\n",
            "river bank    tensor([ 1.5266, -0.8895, -0.5152, -0.9298,  2.8334])\n",
            "Vector similarity for  *similar*  meanings:  0.94\n",
            "Vector similarity for *different* meanings:  0.69\n",
            "0 [CLS]\n",
            "1 [CLS]\n",
            "2 bank\n",
            "3 [SEP]\n",
            "4 [SEP]\n",
            "bank  tensor([ 1.1046,  0.5003, -2.3397, -0.5228, -0.0349])\n",
            "0.44108402729034424\n",
            "0.5723540782928467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLbXrzA0_ndC"
      },
      "source": [
        "# Extracting embeddings from all encoder layers of BERT\n",
        "We learned how to extract the embedding from the pre-trained BERT in the previous section. We learned that they are the embeddings obtained from the final encoder layer. Now the question is should we consider the embedding obtained only from the final encoder layer (final hidden state), or should we also consider the embedding obtained from all the encoder layers (all hidden states)? Let's explore more about this. \n",
        "\n",
        "Instead of taking the embeddings (representation) only from the final encoder layer, the researchers of the BERT have experimented with taking embeddings from different encoder layers.\n",
        "\n",
        "For instance, for a named-entity recognition task, the researchers have used the pre-trained BERT for extracting features. Instead of using the embedding only from the final encoder layer (final hidden layer) as a feature, they have experimented using embedding  from other encoder layers (other hidden layers) as a feature and obtained the following F1 score: \n",
        "<a name=\"table\"></a>\n",
        "$$\n",
        "\\begin{array}{lll}\n",
        "\\textbf{Feature}                 & \\textbf{Notation} & \\textbf{F1 score} \\\\ \\hline\n",
        "\\text{Embeddings}                       & h_0              & 91.0             \\\\\n",
        "\\text{Second to last hidden}            & h_{11}         & 95.6             \\\\\n",
        "\\text{Last hidden}                      & h_{12}         & 94.9             \\\\\n",
        "\\text{Sum of last four hidden} & h_9\\text{ to }h_{12} & 95.9             \\\\\n",
        "\\text{Concat last four hidden}          & h_9\\text{ to }h_{12} & 96.1             \\\\\n",
        "\\text{Sum of all 12 layers}     & h_1\\text{ to }h_{12} & 95.5            \n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "As we can observe from the preceding table, concatenating the embeddings of the last 4 encoder layers (last 4 hidden layers) gives us a greater F1 score of 96.1% in the  NER task. Thus, instead of taking the embeddings only from the final encoder layer (final hidden layer), we can also use embeddings from the other encoder layers.\n",
        "\n",
        "Now, we will learn how to extract the embeddings from all the encoder layers using the transformers library. \n",
        "\n",
        "## Extracting the embeddings \n",
        "First, let us import the necessary modules: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "id": "KSwq5tr9_ndJ"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI91BJ8H_ndJ"
      },
      "source": [
        "\n",
        "Next, download the pre-trained BERT model and tokenizer. As we can notice while downloading the pre-trained BERT model. We need to set `output_hidden_states= True`. By setting this to true helps us to obtain embeddings from all the encoder layers: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "eM0UkRBp_ndK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd618d5-8c17-4dec-ba18-a7459e312b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6lcm9mn_ndK"
      },
      "source": [
        "\n",
        "Next, we preprocess the input before feeding it to the model. \n",
        "\n",
        "## Preprocess the input\n",
        "Let's consider the same sentence we saw in the previous section. First, we tokenize the sentence and add [CLS] token at the beginning and [SEP] token at the end: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "id": "1-hLzFu6_ndL"
      },
      "outputs": [],
      "source": [
        "sentence = 'I love AI'\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "tokens = ['[CLS]'] + tokens + ['[SEP]']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUKVAdmT_ndL"
      },
      "source": [
        "\n",
        "Suppose, we need to keep the token length to 7. So, we add the [PAD] tokens and also define the attention mask: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "id": "5OISI_-t_ndM"
      },
      "outputs": [],
      "source": [
        "tokens = tokens + ['[PAD]'] + ['[PAD]']\n",
        "attention_mask = [1 if i!= '[PAD]' else 0 for i in tokens]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic5yVHnB_ndM"
      },
      "source": [
        "\n",
        "Next, we convert the tokens to their token_ids:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "id": "8YtAw5Gr_ndM"
      },
      "outputs": [],
      "source": [
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MmpLWP6_ndN"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "Now, we convert the token_ids and attention_mask to tensor: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "id": "lm7Nqj6w_ndN"
      },
      "outputs": [],
      "source": [
        "token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
        "attention_mask = torch.tensor(attention_mask).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FQ7RzxU_ndN"
      },
      "source": [
        "\n",
        "\n",
        "Now that we preprocessed the input, let's get the embedding. \n",
        "\n",
        "## Getting the embedding \n",
        "Since we set `output_hidden_states = True` while defining the model for getting the embeddings from all the encoder layers, now the model returns an output tuple with three values as shown below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "id": "DhmqjLG1_ndN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7aeaa24-b8d1-4bc9-e9cc-764e24a9dfcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 7, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "last_hidden_state, pooler_output, hidden_states = model(token_ids, attention_mask = attention_mask).to_tuple()\n",
        "last_hidden_state.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjN7Ojnh_ndO"
      },
      "source": [
        "Again, the first value `last_hidden_state` contains the representation of all the tokens obtained only from the final encoder layer (encoder 12). \n",
        "\n",
        "The `pooler_output` indicates the representation of the [CLS] token from the final encoder layer which is further processed by a linear and tanh activation function. \n",
        "\n",
        "`hidden_states` contains the representation of all the tokens obtained from all the final encoder layers. Lets look at this last one now specifically.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "yzF8Qtxu_ndP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f64491-6e03-4eb0-c506-054330c76beb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "len(hidden_states)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZBdQEeI_ndP"
      },
      "source": [
        "\n",
        "As we can notice, it contains 13 values holding the representation of all layers. Thus: \n",
        "\n",
        "- hidden_states[0] contains the representation of all the tokens obtained from the input embedding layer \n",
        "- hidden_states[1] contains the representation of all the tokens obtained from the first encoder layer \n",
        "- hidden_states[2] contains the representation of all the tokens obtained from the second encoder layer \n",
        "\n",
        "Similarly, hidden_states[12] contains the representation of all the tokens obtained from the final encoder layer \n",
        "Let's explore this more. First, let's print the shape of the hidden_states[0] which contains the representation of all the tokens obtained from the input embedding layer : \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "CUT57PxO_ndQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd90322-52a7-439c-f874-c793e6b599fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 7, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "hidden_states[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPc_0HL3_ndQ"
      },
      "source": [
        "\n",
        "The size [1,7,768] indicates the[batch_size, sequence_length, hidden_size].\n",
        "\n",
        "Now, let's print the shape of hidden_states[1] which contains the representation of all tokens obtained from the first encoder layer : \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Xy_0LBQi_ndR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5816b3a0-e3fa-4b0f-d275-0d54c23a9e6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 7, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "hidden_states[1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2\n",
        "Write down each of the 6 feature vectors from the [table](#table) in this section above only from the `hidden_states` of your model. Define one variable for each."
      ],
      "metadata": {
        "id": "9w5z06xFpIUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### CODE HERE\n",
        "h0=hidden_states[0]\n",
        "print(h0)\n",
        "h11=hidden_states[11]\n",
        "print(h11)\n",
        "h12=hidden_states[12]\n",
        "print(h12)\n",
        "h912=0\n",
        "for i in range(9,13):\n",
        "  h912=h912+hidden_states[i]\n",
        "print(h912)\n",
        "con=torch.cat((hidden_states[9],hidden_states[10],hidden_states[11],hidden_states[12]),dim=0)\n",
        "print('concatenated :'     ,con)\n",
        "h112=0\n",
        "for i in range(1,13):\n",
        "  h112=h112+hidden_states[i]\n",
        "print(h112)\n",
        "\n"
      ],
      "metadata": {
        "id": "1QNYK_6kqmVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e737d1-0cfe-45fe-93d8-b1033fc9a447"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
            "           3.8253e-02,  1.6400e-01],\n",
            "         [-3.4027e-04,  5.3974e-01, -2.8805e-01,  ...,  7.5731e-01,\n",
            "           8.9008e-01,  1.6575e-01],\n",
            "         [ 1.1558e+00,  8.5331e-02, -1.1208e-01,  ...,  4.3965e-01,\n",
            "           8.5903e-01, -3.2685e-01],\n",
            "         ...,\n",
            "         [-3.6430e-01, -1.6172e-01,  9.0174e-02,  ..., -1.7849e-01,\n",
            "           1.2818e-01, -4.5116e-02],\n",
            "         [ 1.6776e-01, -8.9038e-01, -3.1798e-01,  ...,  3.1737e-02,\n",
            "           6.4863e-02,  1.8418e-01],\n",
            "         [ 3.5675e-01, -8.7076e-01, -3.7621e-01,  ..., -7.9391e-02,\n",
            "          -1.0115e-01,  1.9312e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "tensor([[[ 0.1564,  0.1812, -0.0396,  ..., -0.1892, -0.2133,  0.0925],\n",
            "         [ 0.6407,  0.2842,  0.3854,  ..., -0.4780,  0.1137,  0.4909],\n",
            "         [ 0.8315,  0.8067,  0.8561,  ..., -0.8456,  0.6180, -0.2557],\n",
            "         ...,\n",
            "         [-0.0046,  0.0040, -0.0063,  ...,  0.0208, -0.0392,  0.0214],\n",
            "         [ 0.5338,  0.4454,  1.1221,  ..., -0.0626, -0.6434, -0.2897],\n",
            "         [ 0.4147,  0.1194,  1.0373,  ..., -0.0987, -0.7958, -0.2241]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "tensor([[[ 0.0530,  0.3315, -0.0133,  ..., -0.2484,  0.0646,  0.1457],\n",
            "         [ 0.2896,  0.4573,  0.1447,  ..., -0.3118,  0.2678,  0.2486],\n",
            "         [ 0.7214,  0.7312,  0.7564,  ..., -0.4860,  0.3644, -0.3439],\n",
            "         ...,\n",
            "         [ 0.6211,  0.2555, -0.0833,  ..., -0.3117, -0.8269, -0.3043],\n",
            "         [ 0.2268,  0.2171,  0.5064,  ...,  0.0660, -0.1685, -0.0251],\n",
            "         [ 0.1908,  0.0764,  0.4929,  ...,  0.1082, -0.2095, -0.0102]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "tensor([[[-0.0148,  1.2048, -1.1399,  ..., -1.0309, -1.0278,  0.6832],\n",
            "         [ 2.0054,  1.8261,  1.1486,  ..., -1.5996,  0.6602,  1.3295],\n",
            "         [ 3.7979,  3.2308,  3.8057,  ..., -2.9917,  2.1035, -1.5726],\n",
            "         ...,\n",
            "         [ 0.6184,  0.2530,  0.0812,  ..., -0.2979, -1.0132, -0.3877],\n",
            "         [ 1.4175,  1.8496,  3.7807,  ...,  0.9096, -1.5194, -1.7185],\n",
            "         [ 0.9297,  0.6225,  3.0671,  ...,  0.6026, -2.1644, -1.0138]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "concatenated : tensor([[[-6.9848e-02,  3.5556e-01, -6.8201e-01,  ..., -2.3747e-01,\n",
            "          -1.2266e-01,  3.2454e-01],\n",
            "         [ 3.9313e-01,  7.8470e-01,  9.2172e-02,  ..., -3.8901e-01,\n",
            "           2.1504e-01,  4.1932e-01],\n",
            "         [ 1.2590e+00,  8.6880e-01,  1.1305e+00,  ..., -7.6862e-01,\n",
            "           4.6345e-01, -4.0590e-01],\n",
            "         ...,\n",
            "         [ 2.5649e-03, -1.2087e-02,  6.2780e-02,  ..., -7.7121e-02,\n",
            "          -7.5575e-02, -6.8671e-02],\n",
            "         [ 4.3033e-01,  5.1354e-01,  1.0778e+00,  ...,  5.2228e-01,\n",
            "          -2.9823e-01, -8.3215e-01],\n",
            "         [ 2.1977e-01,  1.9352e-01,  6.9630e-01,  ...,  3.0696e-01,\n",
            "          -5.4286e-01, -5.2020e-01]],\n",
            "\n",
            "        [[-1.5436e-01,  3.3646e-01, -4.0501e-01,  ..., -3.5578e-01,\n",
            "          -7.5645e-01,  1.2044e-01],\n",
            "         [ 6.8195e-01,  2.9988e-01,  5.2641e-01,  ..., -4.2081e-01,\n",
            "           6.3662e-02,  1.7072e-01],\n",
            "         [ 9.8608e-01,  8.2410e-01,  1.0626e+00,  ..., -8.9146e-01,\n",
            "           6.5760e-01, -5.6717e-01],\n",
            "         ...,\n",
            "         [-6.2711e-04,  5.5343e-03,  1.0803e-01,  ...,  7.0052e-02,\n",
            "          -7.1498e-02, -3.6153e-02],\n",
            "         [ 2.2655e-01,  6.7355e-01,  1.0744e+00,  ...,  3.8392e-01,\n",
            "          -4.0926e-01, -5.7151e-01],\n",
            "         [ 1.0445e-01,  2.3323e-01,  8.4062e-01,  ...,  2.8613e-01,\n",
            "          -6.1637e-01, -2.5933e-01]],\n",
            "\n",
            "        [[ 1.5638e-01,  1.8121e-01, -3.9613e-02,  ..., -1.8924e-01,\n",
            "          -2.1332e-01,  9.2492e-02],\n",
            "         [ 6.4066e-01,  2.8419e-01,  3.8535e-01,  ..., -4.7802e-01,\n",
            "           1.1373e-01,  4.9091e-01],\n",
            "         [ 8.3148e-01,  8.0670e-01,  8.5610e-01,  ..., -8.4561e-01,\n",
            "           6.1803e-01, -2.5565e-01],\n",
            "         ...,\n",
            "         [-4.6251e-03,  4.0374e-03, -6.2681e-03,  ...,  2.0821e-02,\n",
            "          -3.9160e-02,  2.1383e-02],\n",
            "         [ 5.3379e-01,  4.4538e-01,  1.1221e+00,  ..., -6.2554e-02,\n",
            "          -6.4337e-01, -2.8969e-01],\n",
            "         [ 4.1469e-01,  1.1941e-01,  1.0373e+00,  ..., -9.8722e-02,\n",
            "          -7.9575e-01, -2.2407e-01]],\n",
            "\n",
            "        [[ 5.2992e-02,  3.3152e-01, -1.3284e-02,  ..., -2.4836e-01,\n",
            "           6.4626e-02,  1.4572e-01],\n",
            "         [ 2.8960e-01,  4.5728e-01,  1.4466e-01,  ..., -3.1177e-01,\n",
            "           2.6778e-01,  2.4858e-01],\n",
            "         [ 7.2138e-01,  7.3119e-01,  7.5642e-01,  ..., -4.8600e-01,\n",
            "           3.6438e-01, -3.4392e-01],\n",
            "         ...,\n",
            "         [ 6.2107e-01,  2.5553e-01, -8.3319e-02,  ..., -3.1167e-01,\n",
            "          -8.2692e-01, -3.0428e-01],\n",
            "         [ 2.2680e-01,  2.1712e-01,  5.0636e-01,  ...,  6.5954e-02,\n",
            "          -1.6852e-01, -2.5122e-02],\n",
            "         [ 1.9082e-01,  7.6373e-02,  4.9294e-01,  ...,  1.0819e-01,\n",
            "          -2.0946e-01, -1.0222e-02]]], grad_fn=<CatBackward0>)\n",
            "tensor([[[ 0.5957, -0.8025, -5.0164,  ..., -0.4225, -0.1683,  4.5452],\n",
            "         [ 7.1260,  5.6040,  2.7853,  ..., -1.4896,  1.8014,  1.4297],\n",
            "         [20.0354,  7.4214,  9.2629,  ..., -1.7392,  2.8171, -3.4025],\n",
            "         ...,\n",
            "         [ 0.2429,  0.1595,  0.3308,  ..., -0.8047,  0.0811, -0.5132],\n",
            "         [ 1.5165, -0.9812,  8.6488,  ...,  4.8917, -2.7562, -5.0994],\n",
            "         [ 0.2397, -3.2373,  8.0007,  ...,  3.4126, -4.4319, -3.4209]]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQcW-cj9fowz"
      },
      "source": [
        "# Finetuning BERT for sentiment analysis \n",
        "\n",
        "Let's learn how to finetune the pre-trained BERT for text classification tasks. Say, we are performing sentiment analysis. In the sentiment analysis, our goal is to classify whether a sentence is positive or negative. Suppose, we have a dataset containing sentences along with their labels. \n",
        "\n",
        "Consider a sentence: `I love AI`. First, we tokenize the sentence, add the `[CLS]` token at the beginning, and `[SEP]` token at the end of the sentence. Then, we feed the tokens as an input to the pre-trained BERT and get the embeddings of all the tokens. \n",
        "\n",
        "Next, we ignore the embedding of all other tokens and take only the embedding of `[CLS]` token which is $R_{[CLS]}$. The embedding of the `[CLS]` token will hold the aggregate representation of the sentence. We feed $R_{[CLS]}$ to a classifier (feed-forward network with softmax function) and train the classifier to perform sentiment analysis. \n",
        "\n",
        "Wait! How does it differ from what we saw at the beginning of the section. How finetuning the pre-trained BERT differs from using the pre-trained BERT as a feature extractor?\n",
        "\n",
        "In the first section, we learned that after extracting the embedding $R_{[CLS]}$ of a sentence, we feed the $R_{[CLS]}$ to a classifier and train the classifier to perform classification. Similarly, during finetuning, we feed the embedding of $R_{[CLS]}$ to a classifier and train the classifier to perform classification.\n",
        "\n",
        "The difference is that when we finetune the pre-trained BERT, we can update the weights of the pre-trained BERT along with a classifier. But when we use the pre-trained BERT as a feature extractor, we can update only the weights of a classifier and not the pre-trained BERT. \n",
        "\n",
        "During finetuning, we can adjust the weights of the model in the following two ways:\n",
        "\n",
        "- Update the weights of the pre-trained BERT along with the classification layer \n",
        "- Update only the weights of the classification layer and not the pre-trained BERT. When we do this, it becomes the same as using the pre-trained BERT as a feature extractor\n",
        "\n",
        "The following figure shows how we finetune the pre-trained BERT for the sentiment analysis task:\n",
        "\n",
        "\n",
        "As we can observe from the preceding figure, we feed the tokens to the pre-trained BERT and get the embedding of all the tokens. We take the embedding of `[CLS]` token and feed it to a feedforward network with a softmax function and perform classification. \n",
        "\n",
        "Let's get a better understanding of how finetuning works by getting hands-on with finetuning the pre-trained BERT for sentiment analysis in the next section. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph0nLMVFfow0"
      },
      "source": [
        "\n",
        "\n",
        "Import the necessary modules: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "collapsed": true,
        "id": "xj3OKG3Pfow1"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer, TrainingArguments\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0hcjGwZfow2"
      },
      "source": [
        "\n",
        "Load the model and dataset. First, let's download and load the dataset using the `datasets` library. We only take the first 20 percent from the training set and the first 5 percent from the test set, otherwise the training will take too long."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "train_set = load_dataset(\"imdb\", split=\"train[:25%]\")\n",
        "test_set = load_dataset(\"imdb\", split=\"test[:10%]\")"
      ],
      "metadata": {
        "id": "4yV3HpnkvM6p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "22750072665f47cba0bbdcf55c19900d",
            "ce816309582146b7affcf6ec863776f2",
            "6c41af6a01954435a338194b617b5237",
            "b402d59fa4224f21ad10b25f9a161d90",
            "bccf47b87c504f8caed8c0e70a0f4807",
            "9a001ae00cfe4d2689071712fba03629",
            "3e17db3b1946441b8a914241b46a5dee",
            "9e3433ae666944539e72934e9e041ab2",
            "d79aceeba8f8420eb47c99f0cd4963c7",
            "b703f4c443654d099601f6339aa0b075",
            "08bf966551ca4a2bbfde761174d3a200",
            "44c6a892b26048cf9ca44eaed7e30332",
            "7ab719d2eb6e4332b97d17108b0d4c35",
            "71947082a93644d895ae40567e23c127",
            "facbd767d3ca4f3593b65bd032d795fa",
            "04f44e8496d244ae94c4d763a1102245",
            "dc28c74422d6421c91d62a1f87159a19",
            "9dc5864bddfb47ecbae216dd70be9dc5",
            "11b644504b4d4d20ab5e0cecbfbed89e",
            "23454c7b9d274e2c809868bf7bc999fb",
            "7f20fbad7e694fca83bad610bfd98ccf",
            "cdab3e968b33466d877a5cb303e51f9a",
            "1141cfc750f0467da618c9f51b3d7900",
            "a8425fcc92604668a01a97ac30285b36",
            "b39aa15aee5548daae7eeba867100444",
            "3162ffd79e31483e847ef29c599ca0bd",
            "a0ec08a585a442d3a9276d5cb55b3028",
            "3ccc49969dd340b9a72f74f0aa12a2e4",
            "480ee92d88b94c81956ca2ecb8e3c8a4",
            "9e67487bda284c94a36682b6b0f7ea65",
            "a4393e771f654786ad556ed76652c867",
            "8cf0ddb95a14438999966a66a80a6833",
            "0e07131ac4324ebdbbed1e15e3cc17be",
            "0e4f3eeb4af44efb9e75a3734ae1a66d",
            "eda208717307420d8418b04a02d32210",
            "8ff1b67e3be74c35b124cf5940729118",
            "c5c36259c9664347bfa0033145112321",
            "7981a3dc73e24b4d9364c722bd09ae26",
            "e41382ef33b44afdaa5dbee6425f0811",
            "b2a685ba4e7f4b7a8616a64c0a38be90",
            "79b92f4355c14ba58055640e56c15996",
            "88259d1432764c4dbd481882b64be29a",
            "b8e997379d4c44c8b3838b0d7e167002",
            "73cdb8b1d9b14015b02535f6eb3239fc",
            "5c5695f4747e46fba8073c32dd0cb462",
            "9051657fd5394174b13bbda36498cf8f",
            "5e417fce7a40476ab3fb6eb94c769876",
            "32d44ba6979f41fa9b148c50a573dc37",
            "f68bf7dcbf7646439ae030e85c423721",
            "4828edcd2877458b97b444a9c37e4a1e",
            "ed1dfbdb839f4a41a7a631c3de1d7c02",
            "696d28ea73944bbd9071eccdc23324ef",
            "53a37e9d5f1e467fa579c64694e36afd",
            "6b8ff99ecdf44f3cb3b132d3bfce60db",
            "55ee971ca20c44e19417ae1e252f85b9",
            "577f0cd46f174965aadc5ebcf92280dd",
            "7630641f7620454091713231f350c3ce",
            "efe0c10d61e94809a32f69b462de26a9",
            "ce61d5a5af9a4caca2e0d682c02d82a6",
            "948422e5f11b4a379be299158fcdfd30",
            "a0db6003fe804a72a51faadabe1931e2",
            "7e12760612d0457795a1fcc1f8da8cdb",
            "74a07efab818461f9924795a1a10d748",
            "756cbd099874438e80fdbe4ad2195757",
            "7b1a455635854ad588e585b1e2f48f25",
            "bcd814a4bc8e4d76a1f9dd954254a2a7",
            "6393de89a2fe4d7499d5e680c8964a94",
            "b314e03a72334120813ea236050ba362",
            "aae79434101d4084989e0a9406aad888",
            "a9d0bcd59acb4db3b2c7c143ada079e9",
            "b1044c5b63c0442284005199dcf0cfd2",
            "500d04dd845d453d875efe70d2cdf48c",
            "5f6bf2ac777e4311b8b6eab67649a9a6",
            "1ec526c560b4484a98dbd14a6c8a549a",
            "fdd7fedf064e4146ae7f271dda25b241",
            "c5142ff731634423889d32fc714c7ab8",
            "375e77475d8c409985620010c36b34b8"
          ]
        },
        "outputId": "2897a582-db8f-4cb7-ec5a-8b8501abfb50"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.31k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22750072665f47cba0bbdcf55c19900d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44c6a892b26048cf9ca44eaed7e30332"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.59k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1141cfc750f0467da618c9f51b3d7900"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset imdb/plain_text to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e4f3eeb4af44efb9e75a3734ae1a66d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c5695f4747e46fba8073c32dd0cb462"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "577f0cd46f174965aadc5ebcf92280dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6393de89a2fe4d7499d5e680c8964a94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGrz_f_cfow-"
      },
      "source": [
        "\n",
        "Let's print the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Vd-gEqVcfow_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ff7412e-617b-4aaf-97a5-b025fb2e0958"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 6250\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "train_set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the test set:"
      ],
      "metadata": {
        "id": "2y0VIRPgAuXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set"
      ],
      "metadata": {
        "id": "5_japhwbAvzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd574cc-fa94-4df9-9781-705da7532d21"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 2500\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGi62VtxfoxA"
      },
      "source": [
        "\n",
        "Next, let's download and load the pre-trained BERT model. In this example, we use the pre-trained bert-base-uncased model. As we can observe below, since we are performing sequence classification, we use the BertForSequenceClassification class: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "yNoC_WX2foxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a69bd6f-73ad-44bd-882a-2529c30f4ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW5wD22HfoxC"
      },
      "source": [
        "\n",
        "Next, we download and load the tokenizer which is used for pretraining the bert-base-uncased model.\n",
        "As we can observe, we create the tokenizer using the BertTokenizerFastclass instead of BertTokenizer. The BertTokenizerFast class has many advantages compared to BertTokenizer. We will learn about this in the next section: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "szVRFKRpfoxC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cda79b674acc4f82aa97e0ca354a5c9c",
            "671f7310e29e401e8e15fbf9a8e85488",
            "5b809857934a4186aa442ea894947dd4",
            "c57e1a7fe24742d297d0420a24af44e7",
            "c891c8eb378447059e1a9a5e4716b9bc",
            "5e7b157deacd484fb2e3234ffbcdbfbb",
            "3d1923196fe140fcb3da0b204731ac9d",
            "ab33e911fa4840b3b2991fb44327df84",
            "d1eb3dff7fa143c2999afc048d35c160",
            "25eb838c6f30488aadb1ad4317f2ac2d",
            "c7353d4c97a14b539429b2b10f023feb"
          ]
        },
        "outputId": "9622ef08-7711-4be4-ea08-c51ec8779df5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cda79b674acc4f82aa97e0ca354a5c9c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i95cBPtjfoxC"
      },
      "source": [
        "\n",
        "Now that we loaded the dataset and model, next let's preprocess the dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poYE4BPPfoxD"
      },
      "source": [
        "## Preprocess the dataset\n",
        "We can preprocess the dataset in a quicker way using our tokenizer. For example, consider the sentence: 'I love AI'.  \n",
        "\n",
        "First, we tokenize the sentence and add the `[CLS]` token at the beginning and `[SEP]` token at the end as shown below: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "dHfQQv6pfoxD"
      },
      "source": [
        "```\n",
        "tokens = [ [CLS], I, love, AI, [SEP] ]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHj9t1KrfoxE"
      },
      "source": [
        "\n",
        "Next, we map the tokens to the unique input ids (token ids). Suppose the following are the unique input ids (token ids):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "FzduZUwOfoxE"
      },
      "source": [
        "```\n",
        "input_ids = [101, 1045, 2293, 3000, 102]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJpZf_A5foxE"
      },
      "source": [
        "Then, we need to add the segment ids (token type ids). Wait, what are segment ids? Suppose we have two sentences in the input. In that case, segment ids are used to distinguish one sentence from the other. All the tokens from the first sentence will be mapped to 0 and all the tokens from the second sentence will be mapped to 1. Since here we have only one sentence, all the tokens will be mapped to 0 as shown below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "sLmIG0k3foxF"
      },
      "source": [
        "```\n",
        "token_type_ids = [0, 0, 0, 0, 0]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai4H-92NfoxG"
      },
      "source": [
        "\n",
        "Now, we need to create the attention mask. We know that an attention mask is used to differentiate the actual tokens and `[PAD]` tokens. It will map all the actual tokens to 1 and the `[PAD]` tokens to 0. Suppose, our tokens length should be 5. Now, our tokens list has already 5 tokens. So, we don't have to add `[PAD]` token. Then our attention mask will become: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "aixDEWsTfoxH"
      },
      "source": [
        "```\n",
        "attention_mask = [1, 1, 1, 1, 1]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6ULeBtifoxI"
      },
      "source": [
        "\n",
        "That's it. But instead of doing all the above steps manually, our tokenizer will do these steps for us. We just need to pass the sentence to the tokenizer as shown below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "_EujRhGsfoxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1001f9-7a2a-4603-cac6-740483622b54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1045, 2293, 9932, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "tokenizer('I love AI')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by2HeGksfoxN"
      },
      "source": [
        "\n",
        "With the tokenizer, we can also pass any number of sentences and perform padding dynamically. To do that, we need to set padding to True and also the maximum sequence length. For instance, as shown below, we pass three sentences and we set the maximum sequence length, max_length to 5:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "wwW-9n96foxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54f5daa-5ccb-43e3-e0e8-1166fcefdad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2323: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 1045, 2293, 9932, 102], [101, 5055, 4875, 102, 0], [101, 4586, 2991, 102, 0]], 'token_type_ids': [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1], [1, 1, 1, 1, 0], [1, 1, 1, 1, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "tokenizer(['I love AI', 'birds fly','snow fall'], padding = True, max_length=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2QyIyEefoxO"
      },
      "source": [
        "\n",
        "That's it, with the tokenizer, we can easily preprocess our dataset. So we define a function called preprocess for processing the dataset as shown below: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "collapsed": true,
        "id": "TYpvRZcnfoxP"
      },
      "outputs": [],
      "source": [
        "def preprocess(data):\n",
        "    return tokenizer(data['text'], padding=True, truncation=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwV4SLYDfoxP"
      },
      "source": [
        "\n",
        "Now, we preprocess the train and test set using the preprocess function. The dataset loader still shows 0/1 when its done, its a known [bug](https://github.com/huggingface/datasets/issues/5117) in the library. Your dataset is still preprocessed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "MUyB2AXKfoxQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "4977af27c68146659c757bb11f480acf",
            "0d83c4739f074fb4a8c2a92962edd97e",
            "916101eb20dc407485bc15d52be33969",
            "409651118c1b4ee9b159b5010ab46ca3",
            "eb54fbae80c64d17a5bce7d485cd6416",
            "09a52419f7d94b9299494de430276d59",
            "4a0154107d8947379507539d22a181cd",
            "9d89bdeb61c94e19910fd7081d88889b",
            "3b59502c1ee8465ca4b75e89adb07d39",
            "99372228995f4b34bb6d887d8cde10cc",
            "f21f7f7aafda45dd9cbf197800668f33",
            "dc77fdd4e6744f0280b9120337d55d08",
            "50fd4db9a6b648a1961692fcb17a4524",
            "e081a14d34084b209ce01b1ad1328f74",
            "0ad7b9b376334b5c8c2e44059fcf61dc",
            "40810f9700fe4138ab5178fbcba9bcd4",
            "4694471a75194a9290b9ad493caf2ae6",
            "1a079aa0eddd4a9190b59e4481f1d88f",
            "c89ac9a6c0444780b269fbf38bc4f356",
            "31da2753a2c04643b6326e0610b4712a",
            "07919679cc6a4d03960925d6946cc115",
            "d0ee380013fe4a67a17cf4fa5f9fc8af"
          ]
        },
        "outputId": "6a5d85cd-3c49-40b8-8c0b-35de45d4cd93"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4977af27c68146659c757bb11f480acf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc77fdd4e6744f0280b9120337d55d08"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_set = train_set.map(preprocess, batched=True, batch_size=len(train_set))\n",
        "test_set = test_set.map(preprocess, batched=True, batch_size=len(train_set))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[0].keys()"
      ],
      "metadata": {
        "id": "9gUgYFlL3XVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf2c4035-17bb-48ad-a86d-3982f86b12bb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZHwUC-NfoxR"
      },
      "source": [
        "That's it. Now that we have the dataset ready, let's train the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv67exnifoxR"
      },
      "source": [
        "## Training the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih63Z2wqfoxS"
      },
      "source": [
        "\n",
        "Define the batch size and epoch size.\n",
        "\n",
        "Batch size is how many items we put in per loop. So a batch size of 8 means 8 items per rendering. We need to do this because of the memory allocation of the GPU, its impossible to do the whole dataset at once, because this otherwise wouldn't fit in the GPU.\n",
        "\n",
        "The number of epochs is how many times we loop over the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "collapsed": true,
        "id": "1NjA0cFGfoxT"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "epochs = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSLvaWr6foxT"
      },
      "source": [
        "\n",
        "Define the warmup steps and weight decay.\n",
        "\n",
        "Warmup steps means that in the beginning of training we set the learning to a really slow amount (slow learning rate). We let our network components kind of get used to our dataset, before we really move a lot in our optimization. \n",
        "\n",
        "We use weight decay to avoid overfitting by adding a penalty to our training function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "collapsed": true,
        "id": "6bLTXRGQfoxU"
      },
      "outputs": [],
      "source": [
        "warmup_steps = 500\n",
        "weight_decay = 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brs5HIfufoxU"
      },
      "source": [
        "Lets first define what metrics we want to compute. We deal with binary classification, so it makes sense to include precision, recall, f1 and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {'accuracy': acc, 'f1': f1.item(), 'precision': precision.item(), 'recall': recall.item()}"
      ],
      "metadata": {
        "id": "CIxGbGDzRHWo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how you would define your training loop in the `transformers` library: We can put things in like the number of training epochs, batch size, warmup steps and weight decay. Now lets define the training arguments:"
      ],
      "metadata": {
        "id": "rWalfyRTRNL2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "06c9nd-DfoxU"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_dir='./logs',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOqwu_F8foxV"
      },
      "source": [
        "\n",
        "\n",
        "Now define the trainer: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "collapsed": true,
        "id": "EA70qZzsfoxV"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=test_set\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjOdmJKDfoxV"
      },
      "source": [
        "Start training the model. The training takes about 10 minutes in total!\n",
        "\n",
        "Please make sure you are on GPU, otherwise this takes even longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ce_yJaLwfoxW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "fc5017f8-c660-40be-e209-a12ef4241c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 6250\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 782\n",
            "  Number of trainable parameters = 109483778\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 23/782 17:17 < 10:25:07, 0.02 it/s, Epoch 0.03/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         )\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1747\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2525\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2526\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at-qPxJIfoxW"
      },
      "source": [
        "\n",
        "After training we can evaluate the model using the evaluate function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7sE13FDfoxW"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3\n",
        "1. Instead of using the `Trainer` function from the `transfomers` library, now write your own training loop using **only PyTorch**. You should also implement weight decay and use a linear scheduler. Train for 1 epoch.\n",
        "2. Write an evaluation loop on your test data. Implement `f1`, `accuracy`, `precision` and `recall` and evaluate your model. "
      ],
      "metadata": {
        "id": "U3bgs1CD5kpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## CODE HERE\n",
        "from transformers import BertForSequenceClassification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.train()\n",
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(),lr=1e-5)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 1\n",
        "total_steps = len(train_set) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = 0,num_training_steps = total_steps)\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(train_set, shuffle=True, batch_size=8)\n",
        "test_dataloader = DataLoader(test_set, batch_size=8)\n",
        "for batch in train_dataloader:\n",
        "  encoding = tokenizer(batch, return_tensors='pt', padding=True, truncation=True)\n",
        "  input_ids = encoding['input_ids']\n",
        "  attention_mask = encoding['attention_mask']\n",
        "  labels = torch.tensor([1,0]).unsqueeze(0)\n",
        "  outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "  loss = outputs[0]\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  scheduler.step()        \n",
        "  optimizer.zero_grad()\n"
      ],
      "metadata": {
        "id": "Bj8bdQiCBBYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "for batch in test_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "compute_metrics(true_labels,predictions)\n"
      ],
      "metadata": {
        "id": "20fJ0qhg-MOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrlTQ4RsXU-V"
      },
      "source": [
        "# Fine-tuning Pretrained Transformers for Named Entity Recognition\n",
        "\n",
        "In the previous section we worked on sentiment prediction with just two classes using BERT. In this notebook we'll be using BERT-based models for Named Entity Recognition. Again, exactly the same model, but now we train it for a different dataset. Lets see if we can tag some sentences.\n",
        "\n",
        "One thing to notice is that we now have a different class type within Bert that we going to use. Notice that instead of BertForSequenceClassification we now use BertForTokenClassification. The former we use for predicting labels from a whole piece of text (e.g. sentences). Now we want to classify per token basis. \n",
        "\n",
        "We should reimport the model first, otherwise it is still finetuned on the previous task. That knowledge does not make sense anymore for this task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS2XMkfxXU-f"
      },
      "source": [
        "from transformers import BertForTokenClassification, AutoTokenizer\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased')\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the data\n",
        "Now let's also import a new dataset. This time we are going to work on a PoS dataset. We will be using CoNLL. This dataset contains news stories from Reuters, and contains 3 tasks: part of speech tagging (POS), named entity recognition (NER) and chunking. We import it with the `dataset` library."
      ],
      "metadata": {
        "id": "Eg29QtlmXx2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "id": "Dm6uhuPrXvt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets visualise the structure:"
      ],
      "metadata": {
        "id": "t_UDrabsY4GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "gb2cIFdOY3eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how a token looks like:"
      ],
      "metadata": {
        "id": "glHgqmuuZN8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0][\"tokens\"]"
      ],
      "metadata": {
        "id": "NPl-78tJZNIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how a named entity recognition tag looks like:"
      ],
      "metadata": {
        "id": "BqLl8J2UZP46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0][\"ner_tags\"]"
      ],
      "metadata": {
        "id": "SMlH_cDuZSj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These named entity recognition tags are integers that can be converted with a function back to ones that do have meaning. Let's try it:"
      ],
      "metadata": {
        "id": "BpFvZrMIZXOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner_features = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
        "print(ner_features)"
      ],
      "metadata": {
        "id": "xyFiWarTZiyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So converting above pos tags means we just have to do this:"
      ],
      "metadata": {
        "id": "36e38bEiZpOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = dataset[\"train\"][0][\"tokens\"]\n",
        "labels = dataset[\"train\"][0][\"ner_tags\"]\n",
        "line1 = \"\"\n",
        "line2 = \"\"\n",
        "for word, label in zip(words, labels):\n",
        "    full_label = ner_features[label]\n",
        "    max_length = max(len(word), len(full_label))\n",
        "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
        "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
        "\n",
        "print(line1)\n",
        "print(line2)"
      ],
      "metadata": {
        "id": "N2cw0jfcZr-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets use our tokenizer. We need whole words to perform classification. As we know, a transformers tokenizer splits its content into subwords or bytes. We can solve this with using `tokenizer` as usual and just add `is_split_into_words=True`. For example:\n"
      ],
      "metadata": {
        "id": "bWoWU0JJdZAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(dataset[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
        "inputs.tokens()"
      ],
      "metadata": {
        "id": "WMDR7Fcre0_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, we immediately see a problem. As we can see, the tokenizer added the special tokens used by the model (`[CLS]` at the beginning and `[SEP]` at the end) and left most of the words untouched. The word lamb, however, was tokenized into two subwords, la and ##mb. This introduces a mismatch between our inputs and the labels: the list of labels has only 9 elements, whereas our input now has 11 tokens. Accounting for the special tokens is easy (we know they are at the beginning and the end), but we also need to make sure we align all the labels with the proper words.\n",
        "\n"
      ],
      "metadata": {
        "id": "27bd4_uhfYRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.word_ids()"
      ],
      "metadata": {
        "id": "bs96TzPYfWUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the labels, we have the problem that the `CLS` token and `SEP` token are not really pos tags, and since the word ids are splitted up, we need to create a function that can map parts of words to tokens. We remove the two tokens and parts of subwords by changing them in the align function to `-100`:"
      ],
      "metadata": {
        "id": "do2ph-K71tGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            current_word = word_id\n",
        "            label = -100 if word_id is None else labels[word_id]\n",
        "            new_labels.append(label)\n",
        "        else:\n",
        "            new_labels.append(-100)\n",
        "\n",
        "    return new_labels"
      ],
      "metadata": {
        "id": "BrSRZt_A2BWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = dataset[\"train\"][0][\"ner_tags\"]\n",
        "word_ids = inputs.word_ids()\n",
        "print(labels)\n",
        "print(align_labels_with_tokens(labels, word_ids))"
      ],
      "metadata": {
        "id": "xMNKmfOT2mHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To preprocess our whole dataset, we need to tokenize all the inputs and apply `align_labels_with_tokens()` on all the labels. To take advantage of the speed of our fast tokenizer, it’s best to tokenize lots of texts at the same time, so we’ll write a function that processes a list of examples and use the `Dataset.map()` method with the option `batched=True`. The only thing that is different from our previous example is that the `word_ids()` function needs to get the index of the example we want the word IDs of when the inputs to the tokenizer are lists of texts (or in our case, list of lists of words), so we add that too:"
      ],
      "metadata": {
        "id": "J0E5xmmM4tV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    new_labels = []\n",
        "    for i, labels in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(i)\n",
        "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "vCYleGBF4uu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we haven’t padded our inputs yet; we’ll do that later, when creating the batches with a data collator.\n",
        "\n",
        "We can now apply all that preprocessing in one go on the other splits of our dataset:\n",
        "\n",
        "Please note that the loading function does not fully load to 100%, and the loading bar shows a red color! This is due to a bug in the [datasets](https://github.com/huggingface/datasets/issues/5117) library."
      ],
      "metadata": {
        "id": "rkP1UF_s4y9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = dataset.map(align_labels, batched=True, remove_columns=dataset[\"train\"].column_names)"
      ],
      "metadata": {
        "id": "-6wOBUUh40X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning the model:"
      ],
      "metadata": {
        "id": "585lEPiy_qm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The actual code using the Trainer will be the same as before; the only changes are the way the data is collated into a batch and the metric computation function.\n",
        "\n",
        "With the data collator, our labels should be padded the exact same way as the inputs so that they stay the same size, using -100 as a value so that the corresponding predictions are ignored in the loss computation."
      ],
      "metadata": {
        "id": "R_zlIE-2AJHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
        "print(\"Padded:\")\n",
        "print(batch[\"labels\"])\n",
        "print(\"Not padded:\")\n",
        "for i in range(2):\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
      ],
      "metadata": {
        "id": "HDp8FTwS_dqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To have the `Trainer` compute a metric every epoch, we will need to define a `compute_metrics()` function that takes the arrays of predictions and labels, and returns a dictionary with the metric names and values.\n",
        "\n",
        "The traditional framework used to evaluate token classification prediction is [seqeval](https://github.com/chakki-works/seqeval). To use this metric, we first need to install the *seqeval* and the *evaluate* libraries and then load it in:"
      ],
      "metadata": {
        "id": "ScXYHsiKA5kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq seqeval evaluate\n",
        "import evaluate\n",
        "metric = evaluate.load(\"seqeval\")"
      ],
      "metadata": {
        "id": "gc6YNptoAlGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This metric does not behave like the standard accuracy: it will actually take the lists of labels as strings, not integers, so we will need to fully decode the predictions and labels before passing them to the metric. Let’s see how it works. First, we’ll get the labels for our first training example:"
      ],
      "metadata": {
        "id": "KpBNIFA_BggJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = dataset[\"train\"][0][\"ner_tags\"]\n",
        "labels = [ner_features[i] for i in labels]\n",
        "predictions = labels.copy()\n",
        "predictions[2] = \"O\"\n",
        "metric.compute(predictions=[predictions], references=[labels])\n"
      ],
      "metadata": {
        "id": "aVu2TdhTBjbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets now define a `compute_metrics()` function:"
      ],
      "metadata": {
        "id": "gjBVicfSNngc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[ner_features[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [ner_features[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "kAswlNExKTq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are working on a token classification problem, we will use the `AutoModelForTokenClassification` class. The main thing to remember when defining this model is to pass along some information on the number of labels we have. The easiest way to do this is to pass that number with the num_labels argument, but if we want a nice inference widget working like the one we saw at the beginning of this section, it’s better to set the correct label correspondences instead.\n",
        "\n",
        "They should be set by two dictionaries, `id2label` and `label2id`, which contain the mappings from ID to label and vice versa:"
      ],
      "metadata": {
        "id": "I8lYwZqkNymm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "id2label = {i: label for i, label in enumerate(ner_features)}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ],
      "metadata": {
        "id": "JoQ3zkRjN4-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets run the model! Make sure you are on your GPU, otherwise it will take ages again."
      ],
      "metadata": {
        "id": "9qD_zj0VRSl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "frktK1AJOJ0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "jAPpdDrrmABj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4\n",
        "Now instead of named entity recognition, try finetuning a `bert-base-uncased` model on **part of speech (POS)** tagging. Use the code above, or base your model from the original source of this section from [chapter 7.2 of the HuggingFace Course](https://huggingface.co/course/chapter7/2). You should still use the same dataset, this time instead of the `ner_tags` you use the `pos_tags`. Evaluate also with the `seqeval` library like showed above. You will get errors like `UserWarning: ... seems not to be ...`, you should ignore these. Ignoring these totally you can do with something like:\n",
        "```python\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "```\n",
        "Train the model for 2 epochs and report the following metrics from the `seqeval` within the `compute_metrics` function on the validation set: `eval_precision`, `eval_recall` `eval_f1` and `eval_accuracy` (like above)."
      ],
      "metadata": {
        "id": "ddAaOVq6Oq-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### CODE HERE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from transformers import BertForTokenClassification, AutoTokenizer\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased')\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "pos_features = dataset[\"train\"].features[\"pos_tags\"].feature.names\n",
        "print(pos_features)\n",
        "words = dataset[\"train\"][0][\"tokens\"]\n",
        "labels = dataset[\"train\"][0][\"pos_tags\"]\n",
        "line1 = \"\"\n",
        "line2 = \"\"\n",
        "for word, label in zip(words, labels):\n",
        "    full_label = pos_features[label]\n",
        "    max_length = max(len(word), len(full_label))\n",
        "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
        "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
        "\n",
        "print(line1)\n",
        "print(line2)\n",
        "inputs = tokenizer(dataset[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
        "inputs.tokens()\n",
        "inputs.word_ids()\n",
        "def align_labels_with_tokens(labels, word_ids):\n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            current_word = word_id\n",
        "            label = -100 if word_id is None else labels[word_id]\n",
        "            new_labels.append(label)\n",
        "        else:\n",
        "            new_labels.append(-100)\n",
        "\n",
        "    return new_labels\n",
        "labels = dataset[\"train\"][0][\"pos_tags\"]\n",
        "word_ids = inputs.word_ids()\n",
        "print(labels)\n",
        "print(align_labels_with_tokens(labels, word_ids))\n",
        "def align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    new_labels = []\n",
        "    for i, labels in enumerate(examples[\"pos_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(i)\n",
        "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    return tokenized_inputs\n",
        "tokenized_datasets = dataset.map(align_labels, batched=True, remove_columns=dataset[\"train\"].column_names)"
      ],
      "metadata": {
        "id": "rXuJbd1IQruM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
        "print(\"Padded:\")\n",
        "print(batch[\"labels\"])\n",
        "print(\"Not padded:\")\n",
        "for i in range(2):\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])\n",
        "labels = dataset[\"train\"][0][\"pos_tags\"]\n",
        "labels = [pos_features[i] for i in labels]\n",
        "predictions = labels.copy()\n",
        "predictions[2] = \"O\"\n",
        "metric.compute(predictions=[predictions], references=[labels])\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[ner_features[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [ner_features[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "OPbF5VjZQryE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "id2label = {i: label for i, label in enumerate(pos_features)}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "NQYrtvRmQr15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "smK0kCjf_TDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BERT and other Languages"
      ],
      "metadata": {
        "id": "KATZhoamXJH5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNSb2vhtFOzp"
      },
      "source": [
        "## Multilingual BERT (m-BERT)\n",
        "\n",
        "BERT gives the representation for only the English text. Let's suppose we have an input text in a different language, say, French, now how we can use the BERT for obtaining the representation of the French text? Here is where we use an M-BERT. \n",
        "\n",
        "The multilingual BERT shortly known as M-BERT is used for obtaining the representation of text in different languages and not just English. We learned that the BERT model is trained with masked language modeling and next sentence prediction tasks using the English Wikipedia text and the Toronto BookCorpus. Similar to BERT, the M-BERT is also trained with masked language modeling and next sentence prediction tasks but instead of using the Wikipedia text of only English language, M-BERT is trained using the Wikipedia text of 104 different languages. \n",
        "\n",
        "But the question is, the size of the Wikipedia text for some languages would be higher than the other right? Yes! the size of Wikipedia text would be large for high-resource languages like English compared to low-resource languages like Swahili. If we train our model with this dataset then it will lead to the problem of overfitting. To avoid overfitting, we use sampling methods. We apply under sampling for high-resource languages and over-sampling for low-resource languages. \n",
        "\n",
        "Since the M-BERT is trained over Wikipedia text of 104 different languages, it learns the general syntactic structure of different languages. The M-BERT consists of 110K shared WordPiece vocabulary across all the 104 languages. \n",
        "\n",
        "The M-BERT understands the context from different languages without any paired or language aligned training data. It is important to note that we have not trained M-BERT with any cross-lingual objective, it is trained just like how we trained the BERT model. The M-BERT produces a representation that generalizes across multiple languages for downstream tasks. \n",
        "\n",
        "The original pretrained M-BERT model is open-sourced by Google and it can be downloaded from [here](https://github.com/google-research/bert/blob/master/multilingual.md). The various configurations of pre-trained M-BERT models provided by Google are given in the following: \n",
        "\n",
        "- BERT-base, Multilingual cased \n",
        "- BERT-base, Multilingual uncased\n",
        "\n",
        "Both of the preceding models consist of 12 encoder layers, 12 attention heads, 768 hidden zie. It consists of a total of 110 million parameters. \n",
        "\n",
        "The pre-trained M-BERT is also compatible with the Hugging Face's transformers library. So, we can use it with the transformers library just like how we use the BERT. Let us see how to use the pre-trained M-BERT model and obtain the sentence representation: \n",
        "\n",
        "First, let's import the necessary modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TzB07ZdoFOz2"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertLMHeadModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW2XZfxPFOz3"
      },
      "source": [
        "\n",
        "Download and load the pre-trained M-BERT model and the tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hL-85_FhFOz4"
      },
      "outputs": [],
      "source": [
        "mbert = BertLMHeadModel.from_pretrained('bert-base-multilingual-cased')\n",
        "mbert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDcoOMN9FOz5"
      },
      "source": [
        "Lets try a french sentence on a masked language modelling perspective. This is the task that BERT originally was trained on. Specific words in the sentence were masked, and the goal for the model was to predict them.\n",
        "\n",
        "Lets put the sentence through a tokenizer first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lOsTFIMVFOz6"
      },
      "outputs": [],
      "source": [
        "inputs = mbert_tokenizer(\"[MASK] est la capitale de la France\", return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHjWY21pFOz6"
      },
      "source": [
        "Feed the tokens to the model, get the logits out of it and decode the sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eykNs5nEFOz6"
      },
      "outputs": [],
      "source": [
        "logits = mbert(**inputs).logits\n",
        "mbert_tokenizer.decode(logits[0].argmax(axis=-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13OSmx5EFOz6"
      },
      "source": [
        "It manages to predict words correctly even in other languages!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XLM-BERT"
      ],
      "metadata": {
        "id": "M3GWbT7gSxwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XLM was released by Facebook as an answer on `BERT` and `M-BERT`. In XLM, they subsample the outputs. XLM uses streams of text, uses byte-pair encoding instead of sentencepiece encoding. Moreover, M-BERT is trained using a masked langauge model objective, where XLM also has a new modeling technique named Translation Language Modeling. It masks tokens out and tries to guess the translation of that specific token.\n",
        "\n",
        "We first need to install an extra library:"
      ],
      "metadata": {
        "id": "UYqNfBVbNxl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq sacremoses"
      ],
      "metadata": {
        "id": "MqJ6YoPInszS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can use the `transformers` implementation like this:"
      ],
      "metadata": {
        "id": "8tHqW0G0VGnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLMTokenizer, XLMWithLMHeadModel\n",
        "import torch\n",
        "\n",
        "xlm_tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-100-1280\")\n",
        "xlm_model = XLMWithLMHeadModel.from_pretrained(\"xlm-mlm-100-1280\")"
      ],
      "metadata": {
        "id": "cwOgR1UbUxDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets try the same task as with M-BERT again! This time instead of the token `[MASK]` we need to put in the token `<special1>`. "
      ],
      "metadata": {
        "id": "Xz9xhtrNdihm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = xlm_tokenizer(\"<special1> est la capitale de la France\", return_tensors=\"pt\")\n",
        "logits = xlm_model(**inputs).logits\n",
        "xlm_tokenizer.decode(logits[0].argmax(axis=-1))"
      ],
      "metadata": {
        "id": "yDSeabGsU5w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm.. That does not look correct.. \n",
        "\n",
        "### Exercise 5\n",
        "Try a few sentences with yourself and evaluate whether you think XLM-BERT or M-BERT should be better in predicting masked words (try it in your own mother tongue to see if it is able to guess words in other languages right!). Also take into account the research papers of the two and compare the results. What do you think? When would you use one over the other?"
      ],
      "metadata": {
        "id": "SESiK-tfdtap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ELABORATE HERE\n",
        "Both M-bert and XLM bERT predict the masked words in Greek reasonably.\n",
        "According to the papers:M-BERT produces a representation that seems to generalize well across languages for a variety of downstream tasks.\n",
        "The main feature that differentiates the two aproaches  is the translation language modeling (TLM) objective which improves crosslingual language model pretraining by leveraging\n",
        "parallel data. TLM naturally extends the BERT\n",
        "MLM approach by using batches of parallel sentences instead of consecutive sentences.XLM can take as training dataset a dataset with parallel sentences in different languages(a sentence in one language is paired with the same sentence in another language). Several different pre-training tasks are proposed for XLM:\n",
        "-causal language modeling (CLM): given a set of words within a sequence, predict the next word\n",
        "-masked language modeling (MLM)\n",
        "-translation language modeling (TLM): similar to MLM, but two parallel sentences in different languages are used as input.For example to predict a masked english word XLM can attend to both the english sentence and its french translation.\n",
        "The third task is not able to be done with the Mbert.I think that XLM Bert has to be used over the MBert when for example the corpus that is used has no a lot of data for specific languages and we want to use these languages for our tasks.In this case XLM Bert will be really helpful because it will use the translated data.Therefore,XLM BERT can be really useful for low-research languages.\n"
      ],
      "metadata": {
        "id": "bkIqslsUjrjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CODE HERE\n",
        "# Mbert \n",
        "inputs = mbert_tokenizer(\"Η πρόβλεψη του [MASK] για αύριο δείχνει βροχές σε όλη τη χώρα\", return_tensors=\"pt\")\n",
        "logits = mbert(**inputs).logits\n",
        "mbert_tokenizer.decode(logits[0].argmax(axis=-1))\n",
        "\n"
      ],
      "metadata": {
        "id": "-gAtJNYDjqZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = mbert_tokenizer(\"Ο [MASK] είναι ο πρωθυπουργός της Ελλάδας \", return_tensors=\"pt\")\n",
        "logits = mbert(**inputs).logits\n",
        "mbert_tokenizer.decode(logits[0].argmax(axis=-1))\n"
      ],
      "metadata": {
        "id": "O0hme-L_Udvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs = mbert_tokenizer(\"Η Ισπανία ανήκει στην Ευρωπαϊκή [MASK] \", return_tensors=\"pt\")\n",
        "logits = mbert(**inputs).logits\n",
        "mbert_tokenizer.decode(logits[0].argmax(axis=-1))"
      ],
      "metadata": {
        "id": "nax9clL9FA4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = mbert_tokenizer(\"[MASK] λέγεται η πρωτεύουσα της Ελλάδας\", return_tensors=\"pt\")\n",
        "logits = mbert(**inputs).logits\n",
        "mbert_tokenizer.decode(logits[0].argmax(axis=-1))\n",
        "\n"
      ],
      "metadata": {
        "id": "HEcwVKVwL4eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = mbert_tokenizer(\"Το [MASK] είναι η πρωτεύουσα της Αγγλίας\", return_tensors=\"pt\")\n",
        "logits = mbert(**inputs).logits\n",
        "mbert_tokenizer.decode(logits[0].argmax(axis=-1))\n"
      ],
      "metadata": {
        "id": "MsX0WroeD705"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = mbert_tokenizer(\"Η [MASK] επανάσταση του 1821\", return_tensors=\"pt\")\n",
        "logits = mbert(**inputs).logits\n",
        "mbert_tokenizer.decode(logits[0].argmax(axis=-1))\n"
      ],
      "metadata": {
        "id": "bwHlhqQQZCpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#xlm bert\n",
        "inputs = xlm_tokenizer(\"Η <special1> είναι η πρωτεύουσα της Ελλάδας\", return_tensors=\"pt\")\n",
        "logits = xlm_model(**inputs).logits\n",
        "xlm_tokenizer.decode(logits[0].argmax(axis=-1))"
      ],
      "metadata": {
        "id": "Ourm9ZUTUnng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = xlm_tokenizer(\"Η πρόβλεψη του <special1> για αύριο δείχνει βροχές σε όλη τη χώρα\", return_tensors=\"pt\")\n",
        "logits = xlm_model(**inputs).logits\n",
        "xlm_tokenizer.decode(logits[0].argmax(axis=-1))\n"
      ],
      "metadata": {
        "id": "2snf5e4yU8NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = xlm_tokenizer(\"Ο <special1> είναι ο πρωθυπουργός της Ελλάδας\", return_tensors=\"pt\")\n",
        "logits = xlm_model(**inputs).logits\n",
        "xlm_tokenizer.decode(logits[0].argmax(axis=-1))"
      ],
      "metadata": {
        "id": "43-tfMSnU-fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs = xlm_tokenizer(\"Η <special1> επανάσταση του 1821\", return_tensors=\"pt\")\n",
        "logits = xlm_model(**inputs).logits\n",
        "xlm_tokenizer.decode(logits[0].argmax(axis=-1))"
      ],
      "metadata": {
        "id": "UZQ4jumJZJ4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = xlm_tokenizer(\"Το <special1> είναι η πρωτεύουσα της Αγγλίας\", return_tensors=\"pt\")\n",
        "logits = xlm_model(**inputs).logits\n",
        "xlm_tokenizer.decode(logits[0].argmax(axis=-1))"
      ],
      "metadata": {
        "id": "11uT8QzCEId-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = xlm_tokenizer(\"Η Ισπανία ανήκει στην Ευρωπαϊκή <special1>\", return_tensors=\"pt\")\n",
        "logits = xlm_model(**inputs).logits\n",
        "xlm_tokenizer.decode(logits[0].argmax(axis=-1))"
      ],
      "metadata": {
        "id": "X9YygSipG1-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = xlm_tokenizer(\"Ο Τιτανικός κυκλοφόρησε το <special1>\", return_tensors=\"pt\")\n",
        "logits = xlm_model(**inputs).logits\n",
        "xlm_tokenizer.decode(logits[0].argmax(axis=-1))"
      ],
      "metadata": {
        "id": "e97IYwywERu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Submission\n",
        "Please share your Colab notebook by clicking File on the top-left corner. Click under `Download` on `Download .ipynb` and upload that file to Canvas."
      ],
      "metadata": {
        "id": "MuPbCIYueiBt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lFL9x_OUelPH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}